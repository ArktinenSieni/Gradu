%% Some text is also inherited from engl_malli.tex by Kutvonen, Erkiö, Mäkelä, Verkamo, Kurhila, and Nykänen.


% STEP 1: Choose oneside or twoside
\documentclass[finnish,twoside,openright]{HYgraduMLDS}
%finnish,swedish

%\usepackage[utf8]{inputenc} % For UTF8 support. Use UTF8 when saving your file.
\usepackage{lmodern} % Font package
\usepackage{textcomp} % Package for special symbols
\usepackage[pdftex]{color, graphicx} % For pdf output and jpg/png graphics
\usepackage[pdftex, plainpages=false]{hyperref} % For hyperlinks and pdf metadata
\usepackage{fancyhdr} % For nicer page headers
\usepackage{tikz} % For making vector graphics (hard to learn but powerful)
%\usepackage{wrapfig} % For nice text-wrapping figures (use at own discretion)
\usepackage{amsmath, amssymb} % For better math
%\usepackage[square]{natbib} % For bibliography
\usepackage[footnotesize,bf]{caption} % For more control over figure captions
\usepackage{blindtext}
\usepackage{titlesec}
\usepackage[titletoc]{appendix}
\usepackage{hyperref}
\usepackage{array}
\usepackage{listings} % For code listing

\onehalfspacing %line spacing
%\singlespacing
%\doublespacing

%\fussy 
\sloppy % sloppy and fussy commands can be used to avoid overlong text lines

% STEP 2:
% Set up all the information for the title page and the abstract form.
% Replace parameters with your information.
\title{SQL:n Oppiminen Datatieteen Menetelmin}
\author{Matti Räty}
\date{\today}
\prof{Professor X or Dr. Y}
\censors{Professor A}{Dr. B}{}
\keywords{layout, summary, list of references}
\depositeplace{}
\additionalinformation{}


\classification{\protect{\ \\
\  General and reference $\rightarrow$ Document types  $\rightarrow$ Surveys and overviews\  \\
\  Applied computing  $\rightarrow$ Document management and text processing  $\rightarrow$ Document management $\rightarrow$ Text editing\\
}}

% if you want to quote someone special. You can comment this line and there will be nothing on the document.
%\quoting{Bachelor's degrees make pretty good placemats if you get them laminated.}{Jeph Jacques} 


% OPTIONAL STEP: Set up properties and metadata for the pdf file that pdfLaTeX makes.
% But you don't really need to do this unless you want to.
\hypersetup{
    bookmarks=true,         % show bookmarks bar first?
    unicode=true,           % to show non-Latin characters in Acrobatâs bookmarks
    pdftoolbar=true,        % show Acrobatâs toolbar?
    pdfmenubar=true,        % show Acrobatâs menu?
    pdffitwindow=false,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    pdftitle={},            % title
    pdfauthor={},           % author
    pdfsubject={},          % subject of the document
    pdfcreator={},          % creator of the document
    pdfproducer={pdfLaTeX}, % producer of the document
    pdfkeywords={something} {something else}, % list of keywords for
    pdfnewwindow=true,      % links in new window
    colorlinks=true,        % false: boxed links; true: colored links
    linkcolor=black,        % color of internal links
    citecolor=black,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

\begin{document}

% Generate title page.
\maketitle

% STEP 3:
% Write your abstract (of course you really do this last).
% You can make several abstract pages (if you want it in different languages),
% but you should also then redefine some of the above parameters in the proper
% language as well, in between the abstract definitions.

\begin{abstract}
Summary of the main contents of the work: topic, methodology and results.

Topics are classified according to the ACM Computing Classification System
(CCS): check command \verb+\classification{}+. A small set of paths (1-3) should be used, starting from any top nodes
referred to bu the root term CCS leading to the leaf nodes. The elements
in the path are separated by right arrow, and emphasis of each element individually can be indicated
by the use of bold face for high importance or italics for intermediate
level. The combination of individual boldface terms may give the reader
additional insight. 
\end{abstract}

% Place ToC
\mytableofcontents

\mynomenclature

% -----------------------------------------------------------------------------------
% STEP 4: Write the thesis.
% Your actual text starts here. You shouldn't mess with the code above the line except
% to change the parameters. Removing the abstract and ToC commands will mess up stuff.
\chapter{Johdanto}

The thesis should have an introduction chapter. Other chapters can be named according to the topic. In the end, some summary chapter is needed; see Chapter~\ref{chapter:Yhteenveto} for an example.

\section{Tutkimuskysymykset}

\begin{itemize}
    \item Miten SQL:n oppimista on tutkittu?
    \begin{itemize}
        \item kirjallisuus
    \end{itemize}
    \item Millä tavoin kurssin tehtävien perusteella ennustaa oppimenestystä?
    \begin{itemize}
        \item Kirjallisuus
    \end{itemize}
    \item Millä tavoin SQL-kurssin oppimenestystä ennustaa kurssin tehtävien perusteella?
    \begin{itemize}
        \item kirjallisuus
        \item tämä data
    \end{itemize}
\end{itemize}


\chapter{Termistöä}



\begin{center}
    \begin{tabular}{|| m{3cm} | m{3cm} | m{8cm} ||} 
        \hline
        Suomeksi                                    & Engalnniksi           &   Selitys \\ [0.5ex] 
        \hline\hline
        (tietokanta)taulu                           & (database) table      & Tietokannan tai SQL:n tietorakenne, johon on säilötty tietokannan yksittäinen looginen kokonaisuus. Taulu koostuu riveistä ja sarakkeista. \\ 
        \hline
        rivi                                        & row                   & Kuvaa tietokantataulussa yksittäistä säilöttyä data-objektia. \\
        \hline
        sarake                                      & column                & Kuvailee tietokantataulun rivin ominaisuuksia. \\
        \hline
        kysely                                      & query                 & Tietokantakyselyllä haetaan tietokannasta rivejä kyselyn määrittämillä rajoitteilla \\
        \hline
        tietokantalauseke                           & database clause       & Tietokantakyselyn tyyppi, esimerkiksi SELECT, tai JOIN \\
        \hline
        ohjattu oppiminen \label{term:supervised}   & supervised learning   & Koneoppimisen laji jossa saadut havainnot yritetään luokitella omaan luokkaansa \\
        \hline
        aineisto                                    & data                  & Kokoelma havaintoja. \\
        \hline
        havainto                                    & observation           & Viitataan myös merkinnällä $X$. Ohjatussa oppimisessa kukin havainto pyritään luokittelemaan johonkin luokkaan. \\
        \hline
        ennuste                                     & feature               & Havainnon ominaisuus. Esimerkiksi ihmisen ikä tai pituus. \\
        \hline
        luokka, vaste                               & class, response       & Ominaisuus joka pyritään ennustamaan kullekin havainnolle $X$. Viitataan merkinnällä $Y$. \\
        \hline
        (SQL-)lauseke                               & (SQL) clause          & Osa SQL-kyselyä. Esimerkiksi JOIN, ORDER BY tai DISTINCT. \\
        \hline
        Ohjattu oppiminen                           & Supervised learning   & Koneoppimisen osa-alue, jossa kullakin aineiston havainnolla on jokin vaste-pari \\ [1ex] 
        \hline
    \end{tabular}
\end{center}


\chapter{Taustaa}

\section{Tietokannat ja hallinnointijärjestelmät}

Tietokanta on kokoelma yhtenäistä tietoa joka on tallennettu siten että se on monen käyttäjän saatavissa erilaisiin tarkoituksiin\cite{pathak2007dbms}.

Tietokannan luomiseen liittyy jonkin yhteisön tarpeeseen tallentaa ja hakea tietoa\cite{tikape2019}. Esimerkisi ohjelmointikurssilla on syytä tallentaa tietoa opiskelijoiden tehtävien etenemisestä.

Tärkein osuus tietokantojen suunnittelussa on oleellisten käsitteiden tunnistaminen. Näin tunnistetaan tiedon säilömistä tarvittavat osa-alueet\cite{tikape2019}. 

Tietokannoissa näitä käsitteistä ilmaistaan kentillä (field), tietueilla (record), tiedostoilla (file) sekä avainkentillä (key field)\cite{pathak2007dbms}.

Kenttä on tietokannan pienin mahdollinen tietoa sisältävä kokonaisuus. Se voi sisältää esimerkiksi merkkijonoja tai numeroita. Esimerkiksi verkkosivun käyttäjiä sisältävässä tietokannassa yksittäinen kenttä voisi sisältää käyttäjän nimen.

Tietue on kokoelma toisiinsa liittyviä kenttiä, jotka yhdessä muodostavat yhden tietokokonaisuuden. Esimerkiksi tietue verkkosivun käyttäjästä voi sisältää käyttäjänimen, sähköpostin ja nimen sisältävät kentät.

Tiedosto on kokoelma kaikista saman muotoisista tietueista. Esimerkiksi tiedosto käyttäjistä sisältää kaikki käyttäjiä kuvaavat tietueet.

Tietokanta puolestaan sisältää kaikki toisiinsa liittyvät tiedostot. Esimerkiksi tiedoston käyttäjistä, ja tiedoston käyttäjien eri rooleista sekä tiedoston käyttäjien lähettämistä viesteistä.

Avainkenttä on kunkin tietueen uniikki tunniste, jolla se on eroteltavissa muista tietueista. Se on avainasemassa tietokannan manipuloimiseen ja tiedon noutamiseen tietokannasta.

Tietokantojen ylläpitoon käytetään tietokantahallintajärjestelmiä (database management system). Tietokantahallintajärjestelmien ominaisuuksiin kuuluu muun muassa tiedon eheyden valvominen ja käyttöoikeuksien valvominen\cite{tikape2019}. 

Esimerkkejä tietokantahallintajärjestelmistä ovat muun muassa PostgreSQL ja MySQL, jotka käyttävät omaa murrettaan SQL-kielestä.

Tämä opinnäytetyö keskittyy relaatiotietokantoihin. Relaatiotietokannoissa tieto esitetään relaatioina eli toisin sanoen taulukkoina\cite{tikape2019}. Yleisemmin näitä kutsutaan tietokantatauluiksi, ja edustavat tietokannan termistössä tiedostoa.

Relaatiotietokannassa rivit edustavat tietokannan tietueita. Kullakin rivillä on attribuutteja, joita edustaa taulukon sarakkeet. Taulukko eli yleisemmin tietokantataulu edustaa tietokannan tiedostoa.


\section{Structured Query Language}

Structured Query Language eli lyhyemmin SQL on relaatiotietokantojen\cite{Codd:1970:RMD:362384.362685} hallinnoimiseen tehty ohjelmointikieli\cite{tikape2019}. Sen avulla tietokantahallintajärjestelmissä voiluoda ja määritellä tietokantojen rakennetta, noutaa tietoa tietokannasta ja pyrkiä takaamaan tietokannan turvallisuus\cite{wilton2005beginning}.

Tietokantataulujen (eli tiedostojen) luominen, tiedon syöttämisen säännöt ja rivien (eli tietueiden) noutaminen tehdään SQL-ohjelmointikielellä. SQL-kieli on luonteeltaan deklaritiivinen ohjelmointikieli\cite{sadiq2004sqlator}, eli kirjoitetuilla kyselyillä pyritään kuvailemaan haluttua lopputulosta. Seuraavana on esimerkki yksinkertaisesta tietokantakyselystä.

\begin{lstlisting}[language=SQL]
    SELECT name, breed, age
    FROM Dogs
    WHERE age BETWEEN 2 AND 5;
\end{lstlisting}

Tässä esimerkissä tietokantataulusta $Dogs$, etsitään rivejä joiden sarakkeiden $age$-arvot ovat lukujen 2 ja 5 välillä. Näistä riveistä pyydetään tuloksena saatavaan tauluun sarakket $name$, $breed$, sekä $age$.

SQL-kielen näennäisestä yksinkertaisesta syntaksista huolimatta se on voimakas kyselykieli, joka mahdollistaa monimutkaisiakin kyselyjä tietokantaan.


\section{SQL:n oppiminen}

SQL on kirjattuna suositelluksi opeteltavaksi aiheeksi tietojenkäsittelytieteen-\cite{acm2013currilum} ja ohjelmistoinsinöörien\cite{swebok} perusopinnoissa. SQL on laajan käyttönsä vuoksi helposti sovellettavissa opintojen ulkopuolella IT-alalla.

Laajasta käytöstä huolimatta SQL vaikuttaa olevan vaikea oppia. Vaikeuksien on arvioitu johtuvan SQL:n deklaratiivisesta luonteesta, ja SELECT-kyselyjen näennäisestä yksinkertaisuudesta\cite{sadiq2004sqlator}.

SQL:n opetus on saanut varsin vähäistä huomiota tieteellisissä piireissä\cite{Taipalus:2019:EFS:3287324.3287359}: esimerkiksi SQL:n vaikeiden osa-alueiden tutkimuksen tulokset ovat tulkinnanvaraisia\cite{Taipalus:2019:EFS:3287324.3287359}. Perinteisesti SQL:n opetuksen tutkimus on kohdistunut opetustyökaluihin ja opiskelijoiden tekemiin virheisiin\cite{Taipalus:2019:EFS:3287324.3287359}. Opetustyökaluihin lukeutuvat esimerkiksi erilaiset e-oppimisohjelmistot.

\subsection{E-oppiminen}

E-oppiminen on ollut tutkimusaiheena kasvavassa suosiossa ainakin vuodesta 2000 alkaen. Se on herättänyt kiinnostusta niin työmaailmassa kuin akateemisissa piireissä. Niiden käyttöä perustellaan mahdollisuudella oppia aktiivisesti tekemällä, sen sijaan että opiskellaan asioita passiivisesti lukemalla\cite{Brusilovsky:2010:LSP:1656255.1656257}. 

E-oppiminen on jaoteltavissa kolmeen luokkaan\cite{sadiq2004sqlator}: hallintajärjestelmiin (management system), yhteisölliseen oppimiseen (collaborative learning) ja kohdennettuihin työkaluihin. Hallintajärjestelmiin lukeutuvat esimerkiksi sovellukset WebCT ja Blackboard. Yhteisölliseen oppimiseen kuuluu erilaiset kommunikointitavat, esimerkiksi foorumit, video-konferenssit tai sähköposti. Kohdennetut työkalut ovat puolestaan esimerkiksi simulaattoreita, interaktiivisia työkaluja sekö monikysymys-tietopankkeja (Multiple Choice Question bank).

Kun harkitaan e-oppimisen käyttöönottoa on huomioitava muun muassa onko teknologian käyttö pedagogisesti ja opetuksellisesti arvokasta käyttökohteessa\cite{sadiq2004sqlator}. Olennaista itse työkalun kehityksessä on käyttökohteen huomioiminen suunnittelussa siten että se tukee oppimista mahdollisimman hyvin. Esimerkiksi luonteva navigointi opetusympäristössä parantaa merkittävästi opetustyökalun käyttöastetta ja sen tarjoamaa hyötyä\cite{Brusilovsky:2010:LSP:1656255.1656257}. Koska e-oppimistyökalut korostavat itseopiskelua, korostuu opettajan läsnäolon puutteessa tarve ymmärtää opiskelijan käsitystä oppimisesta\cite{sadiq2004sqlator}.

Onnistuneesti toteutettuna e-oppimistyökalut tukee opiskelijoittensa syväoppimista opettamastaan aiheestaan\cite{sadiq2004sqlator}.


\subsection{SQL opetustyökalut}

Parhaiten SQL:n oppimisen on havaittu toteutuvan ohjatuissa opetussessioissa ja siten että opiskelijoilla on mahdollisuus huomata virheitään ja oppia virheistään\cite{sadiq2004sqlator}. Yksi tapa näiden saavuttamiseen ovat tehtäväkokoelmat, jotka tarkistaa SQL:n ammattilainen. 

Ratkaisuna tämä on työläs muun muassa suuren opiskelijamäärän ja itse tuloksen tarkistamisen vaikeuden vuoksi. Kyselyjen tarkastaminen voi olla hidasta, sillä saman taulun saamiseen voidaan kirjoittaa erilaisia kyselyitä. Ratkaisun ollessa työläs vaarantuu opiskelijoiden saama yksilöllinen palaute\cite{sadiq2004sqlator}.

Kurssien ohjaajien työmäärän vähentämiseen e-oppimistyökalut ovat luonteva ratkaisu. SQL e-oppimistyökalut, kuten esimerkiksi SQLator tai AsseSQL kuuluvat e-oppimistyökalujen kolmanteen luokkaan eli kohdennettuihin työkaluihin\cite{sadiq2004sqlator}.

Kehitettyjen SQL e-oppimistyökalujen on todettu parantavan opiskelijoiden kurssiarvosanaa, ja saavat käyttäjiltään hyvää palautetta\cite{Brusilovsky:2010:LSP:1656255.1656257}. Suuntaa antava vertailu SQL:n kontekstissa saatiin vertailemalla kahden perättäisen vuoden tenttiarvosanajakaumaa, jossa jälkimmäisenä vuotena käyttöön otettiin SQLator\cite{sadiq2004sqlator}. Tenttiarvosanajakauma parani vuonna jona SQLator otettiin käyttöön.

Kohdennetut e-oppimistyökalut jotka on toteutettu SQL:n oppimiseen, vähentävät ihmisen työn tekemää määrää vaarantamatta oppijoiden saamaa palautetta. Koska tarkistuksen tekee oppimistyökalu, tapahtuu kyselyn oikeellisuuden tarkistaminen nopeasti antaen välitöntä palautetta oppijalle. 

SQLator on esimerkki kohdennetusta e-oppimistyökalusta\cite{sadiq2004sqlator}. Sen kuvaillaan olevan verkko-oppimis työpöytä (online learning workbench). Käytännössä se on interaktiivinen oppiympäristö verkko-pohjaisella käyttöliittymällä, joka mahdollistaa pääsyn oppimisympäristöön kaikkialta internet-yhteyden päästä. SQLatorin kehityksen motivaationa on SQL-kielen laaja käyttö, ja SQL kyselyjen arvioinnin laskennallinen monimutkaisuus. 

Kyselyjen tarkastamisen ollessa SQLator:n tärkein ominaisuus tarjoaa se lisäksi oppijalle oppimateriaalia, turvallisen ympäristön vapaalle harjoittelulle sekä yhteyden opettajiin. Opettajat saavat mahdollisuuden luoda ja muokata tietokantoja ja tietokantakohtaisia tehtäviä. SQLator kerää opiskelijoilta dataa esimerkiksi lokeja etenemisestä ja tehtävien suoritusyrityksistä, jotka mahdollistavat tilastojen keräämisen ja opiskelijoiden tarkkailun sekä plagiarismin tunnistamisen.

SQLatorin lisäksi SQL-kyselykielen opetteluun on olemassa useita e-oppimistyökaluja. Yksittäinen opetustyökalu ei yksinään välttämättä tarjoa opetuksen vaatimia ominaisuuksia. Yksi mahdollisuus on integroida olemassa olevia työkaluja, joissa tuodaan useampi opetusympäristö yhteen käyttöliittymään. Tutkimus olemassa olevien opetustyökalujen yhdistämiseen on vähäistä, ilmeisesti integroitujen työkalujen teknisestä vaikeudesta johtuen\cite{Brusilovsky:2010:LSP:1656255.1656257}.

Integroitujen työkalujen helppokäyttöisyyden varmistamiseksi on Brusilovskyn ym. \cite{Brusilovsky:2010:LSP:1656255.1656257} mukaan mahdollistettava single sign-on, opiskelijoiden toimintojen seuraaminen ja tallennettujen tietojen saatavuus. Tallennetun tiedon on tärkeää olla muodossa josta opiskelijoiden osaamista on mahdollista päätellä.


\subsection{Tutkimusta SQL:n oppimisesta / Opiskelijoiden virheet SQL:ssä}

Taipalus ym. \cite{Taipalus:2019:EFS:3287324.3287359} tekivät tutkimusta opiskelijoiden tekemistä virheistä SQL-opetuskurssilla. Data kerättiin heidän tekemässä verkkosovelluksessa, jossa tavoite-taulu oli näkyvillä koko tehtävän tekemisen ajan. Kun tehtävän tekijä oli yritysten jälkeen tyytyväinen kyselyynsä, hän palautti vastauksen. Eniten heitä kiinnosti pysyvät virheet (persistent error), eli virheet jotka esiintyivät palautetuissa tehtävissä. 

Taipalus ym. \cite{Taipalus:2019:EFS:3287324.3287359} jakoivat tehdyt virheet neljään yläluokkaan: sekaannuksiin (complication), loogisiin-, semanttisiin- sekä syntaktisiin virheisiin. 

Kyselyt joissa on syntaksisia virheitä palauttavat virheilmoituksen ilman tietokantataulua. Syntaktiset virheet ovat käytännössä kirjoitusvirheitä jotka SQL-kielen ympäristö itse havaitsee. Ne ilmenevät muun muassa määrittelemättönä tietokantaobjekteina, väärään järjestykseen asetettuina kyselyinä tai yksinkertaisesti puuttuvana puolipisteenä.

Semanttiset virheet ovat syntaktsiesti oikein eli ne palauttavat tietokantataulun. Niiden tunnistaminen on ilmeistä, vaikka ei kyselyn tavoitetta tietäisikään. Usein ne ilmenevät joko puuttuvina tai toistuvina tietokanta-riveinä. Semanttisesti virheellisillä kyselyillä ei ole käyttökohdetta. 

Taipalus ym. \cite{taipalus2018errors} esitti esimerkin semanttisesta virheestä, jossa kyselyssä etsittiin työntekijöitä joilla kullakin on yksi omaan työtehtävään liittyvä titteli. Tehtävänä oli etsiä managerin ja toimistovirkailijan asemassa olevat työntekijät. Kyselyllä joka täyttää ehdon "toimistovirkailija AND manageri", saadaan tulokseksi aina tyhjä taulu. Tämä johtuu kyseisen tietokannan työntekijä tietokantataulun rajoitteesta, jossa kullakin työntekijällä on yksi titteli, eli yksikään tietokantarivi ei täytä ehtoa jossa joku työntekijä olisi molempien toimistovirkailijan ja managerin asemassa. Tämä on esimerkki semanttisesta virheestä, jossa ilmeisesti sekoitetaan puhutun kielen ja logiikan "ja". Kyselyllä "toimistovirkailija OR manageri", tässä tapauksessa  saataisiin haluttu tulos.

Kuten semnattiset virheet, myös loogiset virheet ovat syntaktisesti oikeita. Niiden tunnistamiseen vaaditaan käsitys ja ymmärrys kyselyn taivoitteesta. Virheet joissa on loogisia virheitä voivat olla hyödyllisiä johonkin toiseen käyttötarkoitukseen. 

Jatkaen edellistä esimerkkiä\cite{taipalus2018errors}, jos tavoitteena on etsiä tietokannan toimistovirkalijoita ja managereita rajoituksella "toimistovirkalija OR manageri", niin virhettä ei ole. Jos kuitenkin tämä ei ole tavoitteena, kyseessä on looginen virhe.

Sekaannukset ovat hieman eri asia loogisiin virheisiin nähden. Sekaannukset eivät vaikuta itse tuloksena saatavaan vastaustauluun. Samalla tavalla kuin semanttiset virheet, ovat sekaannukset ilmeisiä huomata: vastauksena saatava taulu on oikein, mutta itse kysely voitaisiin muodostaa jollakin yksinkertaisemmalla tavalla.

Esimerkkejä sekaannuksista ovat esimerkiksi ylimääräinen SELECT-kysely, tai alikyselyssä sijaitseva ORDER BY-lauseke\cite{taipalus2018errors}.

Yleisin virhe kaikissa SQL kyselyissä ovat syntaktiset virheet\cite{Taipalus:2019:EFS:3287324.3287359, Ahadi:2016:SSM:2839509.2844640}. Luonnollisesti syntaktisten virheiden määrä oli suurempi kurssin alussa, ja vähenivät kurssin edetessä. Ahadi ym. \cite{Ahadi:2016:SSM:2839509.2844640} huomauttivat syntaktisten olevan yleisin virhe, jossa opiskelija päättää luovuttaa jos hän ei saa virhettä ratkaistua. Yleisimmät pysyvien virheiden luokat ovat puolestaan loogiset virheet ja sekaannukset\cite{Taipalus:2019:EFS:3287324.3287359}. Loogiset virheet ovat vaikeita ratkaista, ja tämä oli tapaus myös Taipaluksen ym. \cite{Taipalus:2019:EFS:3287324.3287359} mainitsemalla SQL kurssilla. Loogisten virheiden vaikeuden on ehdotettu juontuvat ihmisen työmuistin luonteeseen, ja tapaan jolla ihminen kääntää ajatuksiaan SQL:ään\cite{SMELCER1995353}. 

Tehtävät joiden ratkaisut vaativat jokaista kuutta SQL-kielen lauseketta tuottivat vaikeuksia\cite{Taipalus:2019:EFS:3287324.3287359}. Tavallisesti tehtävissä käytettiin kolmesta neljää eri lauseketta. Jotkin käsitteet ja konseptit toivat mukaansa itsellensä tyypillisiä virheitä mukaan tilastoihin. Esimerkiksi monitauluisissa kyselyissä esiintyi JOIN-kyselyille tyypillisiä syntaktisia- ja semanttisia virheitä. Yksittäinen yleisin ja pysyvin virhetyyppi nousi kokoamisfunktioiden (aggregation function) käytöstä, aina kun tehtävässä niitä tarvittiin. 


\section{Koneoppiminen}

Koneoppiminen pyörii koostuu kolmen käsitteen ympärillä, joita ovat havainnot $X$, vasteet $Y$ ja funktio $f$.

Havainnot ovat käytännössä dataa, josta halutaan päätellä jotakin. Havaintoja $X$ kutsutaan myös opetusdataksi. Tässä kontekstissa havainnot voivat olla esimerkiksi opiskelijoidan yrityksiä johonkin tehtävään. 

Kullakin havainnolla $X = (X_1, X_2, \dots, X_p)$ on $p$ ennustetta. Tehtäväyrityksissä näitä piirteitä voisivat olla esimerkiksi tehtävän aiheen nimi, tai yrityksen ajankohta.

Vaste $Y$ edustaa arvoa jota pyritään koneoppimisella ennustaa. Tässä kontekstissa yritetään ennustaa onko seuraava tehtäväyritys onnistunut tai mikä on opiskelijan saama kurssin arvosana. 

Koneoppimista soveltaessa oletetaan että kullakin havainnon ennusteella on jonkinlainen suhde vasteeseen $Y$. Tätä suhdetta ilmaistaan seuraavalla yhtälöllä.

\begin{equation}
    Y = f(X) + \epsilon
\end{equation}

Yhtälössä $\epsilon$ ilmaisee virhettä tai kohinaa vasteen arvioimisessa, jota ei onnistuta sisältämään funktioon $f$. Funktio $f$ puolestaan edustaa systemaattista tietoa jota havainto $X$ tarjoaa vasteesta $Y$. Koneoppimisprosessin alussa funktio $f$ on tuntematon, ja prosessin tavoitteena on se selvittää.

Käytännössä suurin osa koneoppimisesta on menetelmiä arvioida funktiota $f(X)$. Sen arvioiminen on mielenkiintoista muun muassa vasteiden määrän ollessa pieni havaintojen määrään nähden, tai ennusteiden ja vasteen suhteen luonteen selvittämiseksi.

Esimerkki tilanteesta jossa ollaan kiinnostuttu vasteen arvioimisesta, voisi olla tilanne jossa halutaan ohjelmointikurssin aikana löytää heikosti menestyvät opiskelijat.

Vastaavasti kun ollaan enemmän kiinnostuneita ennusteiden ja vasteiden suhteesta, tarkasteltaisiin tilannetta jossa ohjelmointikurssi on jo päättynyt. Nyt vasteiden arvioimisen on toissijaista, ja tarkastellaan ennusteita $p$ jotka vaikuttavat vasteeseen $Y$. Esimerkiksi mitkä tekijät vaikuttavat opiskelijoiden arvosanoihin.

Koneoppimista voidaan jaotella usein ohjattuun ja ohjaamattomaan oppimiseen. Joissakin koneoppimismenetelmissä on molempia piirteitä.

Ohjatussa oppimisessa kullakin havainnolla $x_i$ oletetaan olevan jokin vaste $y_i$. Koneoppimismallin opetuksen aikana ainakin osalla opetusdatalla on jo oma vasteensa. Ohjatun oppimisen lopputavoitteena on pystyä antamaan tuleville, vielä tuntemattomille havainnoille asian mukainen vaste. Tämä opinnäytetyö tulee keskittymään tähän koneoppimisen koulukuntaan.

Ohjaamattomassa oppimisessa opetusdatassa ei ole vasteita, eikä vasteisiin kiinnitetä huomiota algoritmin opetuksen aikana. Yksi esimerkki ohjaamattomasta oppimisesta on klusteroiminen, jossa annetaan koneoppimis algoritmin ryhmitellä data annettujen havaintojen perusteella.

\subsection{Koneoppimismallien hyvyyden arvioiminen}

Koneoppimismallin menestystä mitataan mallin ennusteiden tarkkuudella. Kuinka hyvin ennustetut vasteet vastaa aitoa vastetta? Riippuen vasteen tyypistä, tähän vastataan hieman eri tavalla.

Jos ennustettava vaste on kvantitatiivinen eli jokin numeroarvo, käytetään usein Mean Squared Error-funktiota\cite{james2013ISLR}.

\begin{equation}
    MSE = \frac{1}{n} \Sigma^n_{i=1} (y_i - \hat{f}(x_i))^2
\end{equation}

Toisin sanoen MSE laskee kuinka paljon ennustetut kvantitatiiviset vasteet eroavat aidosta vasteesta. 

Mitä suurempi MSE on, sitä epätarkempi koulutettu mallin todennäköisesti on.

Jos vaste on puolestaa kvalitatiivinen eli vaste on esimerkiksi jokin luokka, summataan ennustetun vasteen ja aidon vasteen erotuksen sijasta yksinkertaisesti että oliko ennustettu luokka oikea\cite{james2013ISLR}.

\begin{equation}
    CV_{n} = \frac{1}{n} \Sigma^n_{i=1} Err_i
\end{equation}

\begin{equation}
    Err_i = I(\hat{f}(x)_i \neq y_i)
\end{equation}

Tässä jälleen validaatiovirheen ollessa suuri, sitä todennäköisemmin koulutettu malli on suoritukseltaan heikko.

Mallien tarkkuutta voidaan tarkastella mallin koulutuksen ja testaamisen aikana. Koulutuksen aikana tehty validointi tehdään samalla datalla, jolla malli on koulutettu. Testaamisen aikana tehty validointi puolestaan tehdään koulutetulle mallille datalla, jota malli ei ole vielä nähnyt.

Harjoituksen aikana tehty validaatio on enintään suuntaa antava, ja parhaimmillaan voi antaa hyvin tarkkoja ennusteita vasteeksi: antaen siis varsin matalia arvoja. 

Harjoitusdatan validaatio on suuntaa antava metriikka koska malli voi oppia myötäilemään harjoitusdataa liian tarkasti, jonka seurauksena on ylisovittaminen.

Ylisovittamisessa (overfitting) malli myötäilee harjoitusdataa niin uskollisesti, että se ei osaa ennustaa tarkasti harjoitusdatan ulkupuolelta tulevia syötteitä.

Ylisovittamista silmällä pitäen mallia validoidaan datalla jota malli ei ole aikaisemmin nähnyt: testidatalla. Testidataan tehdyn validoinnit ovat harjoitusdataan nähden usein heikompia. Jos malli suoriutuu hyvin testidatalla valdoimisesta, pidetään sitä hyvänä merkkinä.

Testidatalla voidaan helposti validoida, jos on saatavilla suuria määriä harjoitusdatan ulkopuolella olevaa dataa. Useimmissa tapauksissa tämä ei ole kuitenkaan mahdollista. Suurta testidataa voidaan yrittää korvata ottamalla koulutusdatasta validointikokoelma (validation-set). 

Validointikokoelma (tai validointidata) on käytännössä koulutusdatasta otettu satunnainen otos, jota ei laisinkaan anneta mallin käyttöön koulutuksen aikana. Tätä kokoelmaa käytetään mallin kouluttamisen lopussa mallin tarkkuuden arvioimiseen. 

Ristiinvalidointi (cross-validation) vie tätä ajatusta pidemmälle. Harjoitusdata jaetaan $k$ osaan, esimerkiksi $k=5$ osaan. Nyt koulutetaan koneoppimismalli samalla algoritmilla $k$ kertaa siten että kullakin kerralla jätetään yksi osa pois harjoitusdatasta, ja ulos jätettyä osaa käytetään validaatiodatana. 

Ristiinvalidnoinnilla voidaan selvittää kuinka hyvin koneoppimisalgoritmi selviää itsenäisestä datasta. Lisäksi on mielenkiintoista selvittää vaihe, missä validnointivirhe on matalimmillaan\cite{james2013ISLR}. 

Ristiinvalidointi on usein vakio tapa tarkastella koneoppimisalgoritmien suoriutumista\cite{james2013ISLR}.

 
\section{Kurssimenestyksen ennustaminen}

Oli kurssin oppiaiheena mikä tahansa, on kurssin järjestäjien pyrittävä arvioimaan opiskelijoiden suoriutumisesta myös kurssin aikana. Tämä on haastavaa opiskelijoiden tullessa eri taustoilta ja eri opintolinjoilta.

Yksi ehdotettu ratkaisu on ennakkokyselyjen tekeminen kurssin alussa\cite{watson2014no}. Tämä potentiaalisesti tarjoaa yleisnäkymän kurssin osallistujista.

Kyselyt ovat kuitenkin hyödyttömiä opiskelijamäärien ollessa yli sata jokaista kurssiohjaajaa kohden: lomakkeiden läpikäyminen vie liikaa aikaa, ja näin apua tarvitsevat löydetään liian myöhään. Tukea tarvitaan mahdollisimman varhaisessa vaiheessa jotta arvosanoihin voidaan vaikuttaa merkittävällä tavalla\cite{bergin2015using}.

\subsection{Kurssimenestysken ennustaminen ohjelmointikursseilla}

Ohjelmointikurssit joiden tarkoitus on olla opiskelijoiden ensimmäinen kosketus ohjelmointiin ovat vaikeita huomattavalle osuudelle opiskelijoista. Tämä johtaa kursseilta pois jäämiseen ja hylättyihin arvosanoihin sekä heikkoihin arvosanoihin \cite{bergin2015using}. 

Aloittelijoiden ohjelmointikurssien läpipääsymäärä tutkimusaiheena on kasvattanut kasvattanut merkittävästi suosiotaan merkittävästi vuodesta 2009 alkaen\cite{hellas2018predicting}. Kiinnostuksen kasvusta huolimatta maailmanlaajuinen arvioitu läpipääsyjen määrä ohjelmoinnin aloituskursseilla oli noin 68\% vuonna 2014\cite{watson2014failure}. 

Ohjelmointikurssien ennustamisen kohteena ovat usein kurssin loppuarvosana, tenttiarvosana sekä tehtävien kurssiarvosana. 

Yleisimpiä ennustamismenetelmiä ovat tilastolliset menetelmät\cite{hellas2018predicting}. Muita ohjelmointikurssien yhteydessä käytettäviä menetelmiä ovat muun muassa datalouhimis- ja koneoppimismenetelmät. 

Ohjelmointikursseilla data on usein kerätty ohjelmointiympäristön (IDE, Integrated Development Environment) keräämästä tiedosta. Tähän voi sisältyä ohjelmakoodin kääntämisen aikana kerätyt kirjaukset (ts. lokitukset), tai tilannekuvat (snapshot) koko ohjelmakoodista\cite{watson2013predicting, jadud2006methods, lagus2018transfer}.

Tilastollisten menetelmien yhteydessä ennusteiden mallintamiseen on muutamassa tapauksessa käytetty tilakoneita. 

Tilakone on järjestelmä jota kuvataan tiloina ja sen tilojen muutoksina, jonka tila riippuu tilakoneen nykyisestä tilasta ja sen saamasta syötteestä. 

Viitatuimpia tilakoneita jotka pyrkivät mallintamaan ohjelmoivan opiskelijan tehtävien tilaa ovat, Error Quotient\cite{jadud2006methods}, Watson Score\cite{watson2013predicting} sekä Normalized Programming State Model (NPSM)\cite{carter2015normalized}. 

Error Quotient ja Watson Score rakentavat mallinsa oman ohjelmointikielen kääntäjän kääntämis-lokeista, ja näin pyrkivät ymmärtämään aloittelevien ohjelmoijien ohjelmointikääntämiskäyttäytymistä. Nämä mallit tarkastelevat opiskelijoiden virheellisiä sovelluksien kääntämisyrityksiä, ja vetävät johtopäätöksiä perättäisten kääntämiskertojen välillä. 

Error quotient on näistä kahdesta yksinkertaisempi. Se lähinnä tarkastelee perättäisten virheiden tyyppiä. 

Perättäisten virheiden lisäksi Watson Score ottaa käyttöönsä useampia parametreja. Watson Scoren:n käyttämä pääpiirre on virheiden korjaamiseen kuluva aika. Tätä aikaa verrataan samalla kurssilla oleviin opiskelijoihin, ja pisteytetään tämän mukaan. Jos aikaa kului enemmän kuin vertaisilla, lasketaan kyseisen opiskelijan pisteytystä.

NPSM lienee ottanut innoitusta Watson Score:sta. Kuten Watson Score, myös NPSM tarkkailee kulunutta aikaa. NPSM käyttää kuitenkin tarkempaa mallia ja käyttää ajankohtaisempaa dataa. Mallissa otetaan huomioon, oliko ohjelmakoodissa semanttisia- tai syntaktisia virheitä. Näin NPSM muodostaa holistisemman kuvan kunkin opiskelijan ohjelmakoodin tilasta. 

NPSM hyödynsi kääntämislokien lisäksi striimattuja otoksia opiskelijoiden koodista, joita opiskelijoiden ohjelmointiympäristät lähettivät, antaen tarkempaa tietoa esimerkiksi ohjelmakoodin syntaktisesta tilasta. 

Ennustavina menetelminä heikoin on Error Quotient, ja selkeästi vahvin on NPSM huomioitaessa selittävää varianssia\cite{carter2015normalized}. Error Quotient-mallista puuttuu liikaa tietoa ollakseen enemmän kuin suuntaa antava pisteytys\cite{jadud2006methods}. Vaikka Watson Score on tarkempi Error Quotient:iin nähden, on sen käyttämä data paljon suppeampaa verrattuna NPSM:iin\cite{carter2015normalized}. Carter kuitenkin huomautti mahdollisista eroista kurssiasetelmassa, ohjelmistoympäristöissä ja ohjelmointikielissä\cite{carter2015normalized}. 

Kullakin tilakoneella rakennettiin ennustava malli lineaarisella regressiolla. NPSM:a sovellettiin myös multivariate regressioon. Mielenkiintoinen tutkimisen aihe olisi soveltaa näiden tilakoneiden tuottamia parametreja monimutkaisempiin koneoppimismalleihin.

Opiskelijoiden ohjelmointikurssien menestyksen kontekstiin sovellettuja koneoppimistekniikoita on laaja kirjo. Kun kyseessä on akateemisen menestyksen ennustaminen, ovat suosituimpia tekniikoita lineaarinen regressio, ja luokittelualgoritmit\cite{hellas2018predicting}. 

Tarkimpien koneoppimismenetelmien joukkoon kuuluvat muun muassa Naive Bayes\cite{bergin2015using}, tukivektorikoneet\cite{bergin2015using} sekä random forest\cite{lagus2018transfer}. Näistä jokainen on luokittelukoneoppmis-tekniikka. Myös neuroverkot esiintyvät ohjelmoinnin oppimisen ennustamisessa\cite{Castro-Wunsch:2017:ENN:3017680.3017792}. 

Koneoppimisalgoritmien ongelmana on usein niiden joustamattomuus: ne on koulutettava datasta, joka on samanlaista kuin itse käytössä oleva data. Tämä pätee erityisesti klassisiin koneoppimisalgoritmeihin kuten esimerkiksi tukivektorikoneisiin ja logistiseen regressioon. Jos tätä ehtoa ei noudateta, ovat ennusteiden tarkkuudet huomattavan heikkoja. 

Jos koneoppimisalgoritmi koulutetaan kurssia varten ja kurssin aikana, todennäköisesti ongelmaa ei ole. Tavoiteltavaa on kuitenkin saada aikaiseksi malli, jolla on kohtuullinen tarkkuus edes saman kurssin eri toistokerroilla. 

Vaikka ohjelmointikurssilla kurssimateriaali, tavoitteet ja opeteltavat asiat pysyisivät samana vuodesta toiseen, on muuttuvia tekijöitä jokaisella iteraatiokerralla useita: muun muassa osallistujien lähtötaso, opettajat sekä opetusmenetelmät. Muuttuvat tekijät pudottavat ennusteiden tarkkuutta merkittävästi. 

Saman kurssin eri toistoihin sovellettuja algoritmeja on tutkittu muun muassa neuroverkoilla\cite{Castro-Wunsch:2017:ENN:3017680.3017792} ja transfer learning\cite{lagus2018transfer}-tekniikalla.


\subsection{Kurssimenestyksen ennustaminen SQL-kursseilla}

Kurssimenestyksen ennustamisesta SQL-kurssien kontekstissa oli tausta-artikkelien keräämisen hetkellä varsin vähän. Ainoa artikkeli jossa suoraan puhuttiin koneoppimisen soveltamisesta oppilaiden menestyksen ennustamiseen SQL-kurssilla on Ahadin ym. kirjoittama "Students' Syntactic Mistakes in Writing Seven Differente Types of SQL Queries and its Application to Predicting Students' Success"\cite{Ahadi:2016:SSM:2839509.2844640}. Tutkimuksen lähestymistapana on luokitella opiskelijat onnistuneisiin ja epäonnistuneisiin heidän kääntämisyritysten perusteella PART-luokittelijalla.

PART luokittelija on sääntöpohjainen luokitteija joka perustuu C4.5 algoritmiin\cite{Ahadi:2016:SSM:2839509.2844640}. PART valittiin luokittelijaksi koska se hallitsee puuttuvat arvot, ja se tarjoaa selkeän esityksen generoiduista säännöistä. Itse kysymys johon luokittelijalla haettiin vastausta, oli selvittää mikä määrä kamppailua on hyviä ennuste sille että onnistuuko oppilas tuottamaan oikean kyselyn. Luokittelija koulutettiin ennustamaan että onnistuuko oppilas tuottamaan GROUP BY-kyselyn oikein.

Luokittelija sai syötteekseen 480 oppilaan yritykset yhteen tehtävään. Puolet syötteeksi valituista oppilaista onnistui vastaamaan kysymykseen ja puolet eivät. Aineistona PART-luokittelijalle annettiin oppilaitten suorittamat kyselyt, sekä virheelliset että oikein menneet. Ennusteita valittiin (feature selection) korrelaatio-pohjaisilla menetelmillä ylisovittamisen välttämiseksi, ennusteiden päällekkäisyyksien vähentämiseksi ja ennustustarkkuuden parantamiseksi. Koulutettu luokittelija validoitiin kymmenkertaisella cross-validation-menetelmällä. GROUP BY-kyselyn ennustamisessa saavutettiin 77\% tarkkuus.

Kuten edellissä kappaleessa todettiinkin, Ahadi ym. \cite{Ahadi:2016:SSM:2839509.2844640} muistuttavat eri koneopimisalgoritmien olevan voimakkaasti kontekstiriippuvaisia. Samalla tavoitteella koulutetut koneoppimismallit saavuttivat tarkkuuden 60\%:n ja 79\%:n väliltä.


\chapter{Koneoppimisen soveltaminen kurssi-dataan}

\begin{itemize}
    \item meneekö seuraava tehtävä oikein
    \item tuleva tenttiarvosana SQL tehtävissä
\end{itemize}

\section{Data}

Tämän opinnäytetyön aineisto on kerätty Helsingin yliopiston tietokantojen perusteet-kurssilta\cite{tikape2019}. Kurssi on tarkoitettu olemaan tietojenkäsittelytieteen kandidaatin tutkielman opiskelijoiden ensimmäinen kosketus muun muassa tietokantoihin ja SQL:ään\cite{tikape2019}.

Aineisto on kerätty opiskelijoilta jotka kävivät tietokantakurssia vuoden 2019 kevät- ja kesälukukautena. 

Aineistossa on mukana opiskelijoiden saamat arvosanat ja tietokantakurssin aikana tehtyjen tehtävien yritykset.

Aineisto koostuu 293 opiskelijan tuottamasta sisällöstä. (asiaa  arvosanoista: keskiarvoa, hajonta yms. Graafi jakaumasta?)

Tallennettuja tehtäväyrityksiä on aineistossa 876 893. (tilastoja datasta. onnistumis prosenttia, yrityksiä/tehtävä,  yrityksiä/käyttäjä, yritysten määrä tehtävätyypeittäin)


\section{Valitut mentelmät}

\begin{itemize}
    \item supervised learning valittu
\end{itemize}

\begin{itemize}
    \item mikä menetelmä, mukaanlukien matemaattinen selitys?
    \item mikä hyvää/huonoa?
    \item missä käytetty opetuksen kontekstissa?
    \item miksi valittu?
\end{itemize}

\subsection{Bayes luokittelija}

Bayes luokittelija perustuu nimensä mukaisesti bayesin kaavaan\cite{james2013ISLR}. Olettaen että Bayesin luokittelijan ehdot on määritelty oikein, olisi sillä luokittelijoista matalin virheaste\cite{james2013ISLR}.

\begin{equation} \label{eq:bayes}
    Pr(Y = k | X = x) = \frac{\pi_k f_k(x)}{\sum^K_{l=1} \pi_l f_l(x)}
\end{equation}

Viitataan posterioriin $Pr(Y = k | X = x)$ jatkossa merkinnällä $p_k(X)$.

Jotta arvio luokkaan kuulumisesta voidaan tehdä, Bayes luokittelija pyrkii etsimään luokan $k$ joka maksimoi posteriorin $p_k(X)$. 

\begin{equation}
    p^*(X) = \arg \max_k p_k(X)
\end{equation}

Bayes luokittelija antaa todennäköisyyden siitä, että havainto $x$ kuuluu luokkaan $k$.

Bayes luokittelijan ennakkotietoa luokkien todennäköisyyksistä kuvaa priori $\pi_k$. Jos tarkkaa ennakkotietoa todellisesta luokkien todennäköisyydestä ei ole, voidaan se helposti arvioida satunnaisotoksen esiintyvistä luokista: ottamalla kunkin luokan lukumäärän osuus kaikista havainnoista. 

Bayesin kaavan tiheysfunktio $f_k(x)$ on käytännössä ehdollinen todennäköisyys siitä että havinto on jokin $x$ ehdolla että luokka $Y = k$. Siihen viitataan myös merkinnällä $Pr(X = x | Y = k)$. Se on huomattavasti hankalampaa ratkaista suoraan verrattuna yhtälön muihin osiin. Se on laskennallisesti raskasta ja sen todelliset parametrit ovat todellisuudessa saavuttamattomia ilman kaikkea aineistoa. Todellisuudessa siis tiheysfunktiota ei voi ikinä laskea tarkasti, joten todellista arvoa ei käytännössä edes lasketa. Tästä syystä Bayes luokittelijaa pyritään tavalla tai toisella approksimoimaan\cite{james2013ISLR}.


\subsection{Naive Bayes}

Naive Bayes nimensä mukaisesti perustuu Bayesin kaavaan. Se on yksinkertaistettu versio Bayes-optimoidusta luokittelijasta\cite{rish2001empirical}.

Koska kyse on ehdollisesta todennäköisyydestä, on havaintojen ennusteiden määrän kasvaessa tiheysfunktion $Pr(X = x | Y = k)$ ratkaiseminen suoraan laskennallisesti raskasta. Tämän vuoksi naive Bayes tekee rajun yksinkertaistuksen: se oletta että kaikki havaintojen ennusteet ovat toisistaan riippumattomia. Tämä yksinkertaistaa kyseisen ehdollisen todennäköisyyden muotoon $P(\textbf{X}|C) = \Pi^n_{i=1} P(X_i | C)$, jolloin saadaan naive Bayesin funktio diskriminantissa muodossa:

\begin{equation}
    f_k(X) = Pr(X = x | Y = k) = \Pi^n_{n=1} Pr(X = x_i | Y = k)
\end{equation}

\begin{equation}
    f^{NB}_i(\textbf{x}) = \Pi^n_{j=1} P(X_j=x_j | C=i) P(C=i)
\end{equation}

Tässä $j$ on havainnon indeksi, $i$ on luokan indeksi ja $n$ on havaintojen määrä. 

Rajusta yksinkertaistamisestaan huolimatta naive Bayes kilpailee suorituskyvyllään hienostuneempien koneoppimismenetelmien kanssa\cite{rish2001empirical}. Parhaiten se toimii havaintojen kanssa joiden ennusteet ovat toisistaan riippumattomia, ja kun ennusteet ovat toisistaan funktionaalisesti riippuvaisia. 

Naive Bayesin rajoituksen ovat nominaaliset koneoppimisennusteet, eli ennusteet joilla on rajallinen määrä mahdollisia arvoja. Binääristen ennusteiden kohdalla naive Bayes voi oppia vain lineaarisia suhteita, ja kun ennusteiden mahdollisten arvojen määrä ylittää kaksi, on havaintoavaruden oltava polynomisesti jakautunut\cite{rish2001empirical}.

Opetuksessa naive Bayesia on käytetty esimerkiksi koulutuksellisen datan louhintaan\cite{bhardwaj2012data}, ja opiskelijoiden soveltuvuuden arviointiin kirjallisuuden opinnoissa\cite{hellas2018predicting}.

Naive Bayes on valittu menetelmänä mukaan sen saaman menestyksen ja yksinkertaisuuden vuoksi. Bayes-sukuiset menetelmät omaavat kokonaisen tilastotieteen koulukunnan, jonka opetusta löytyy myös Helsingin Yliopistossa. Haluan nähdä tämän yksinkertaisen Bayes-menetelmän sovelluksen käytännössä.


\subsection{Linear Discriminant Analysis}

Linear Discriminant Analysis (LDA) on approksimaatio Bayes luokittelijasta joka pyrkii yksinkertaistamaan havaintojen ennusteavaruuden lineaariseksi. LDA saavuttaa tämän olettamalla tiheysfunktion olevan normaalisti jakautunut, ja estimoimalla havaintojen keskiarvoa $\mu_k, $varianssia $\sigma^2$ sekä prioria $\pi_k$.

Kun havaintojen ennusteista käytetään yhtä ennustetta $p$, käytetään tiheysfunktiona normaalijakauman tiheysfunktiota.

\begin{equation}
    f_k(x) = \frac{1}{\sqrt{2 \pi \sigma_k}} \exp{(-\frac{1}{2 \sigma^2_k (x - \mu_k)^2})}
\end{equation}

Normaalijaakuman tiheysfunktio sijoitetaan Bayesin kaavaan \ref{eq:bayes} ja josta otetaan logaritmi. Näin saadaan funktion lineaarinen diskriminantti funktio.

\begin{equation}
    \delta_k(x) = x \cdot \frac{\mu_k}{\sigma^2} - \frac{\mu^2_k}{2 \sigma^2} + \log(\pi_k)
\end{equation}

Tosiaan koska todelliset arvot keskiarvolle $\mu_k$, yhteiselle varianssille $\sigma^2$ ja priorille $\pi_k$ ovat tuntemattomia, approksimoidaan ne seuraavasti ja sijoitetaan ne vastaaviin paikkoihin funktiossa.

\begin{equation} \label{eq:estimate-mu}
    \hat{\mu}_k = \frac{1}{n_k} \sum_{i:y_i = k} x_i
\end{equation}

\begin{equation}
    \hat{\sigma}^2 = \frac{1}{n - K} \sum^K_{k=1} \sum_{i:y_i = k} (x_i - \hat{\mu}_k)^2
\end{equation}

\begin{equation} \label{eq:estimate-pi}
    \hat{\pi}_k = n_k / n
\end{equation}

Ja näillä arvoilla saadaan todellisen diskriminantin funktion estimaatti $\hat{\delta_k}(x)$. Havainto $x$ luokitellaan luokkaan $k$ jolla $\hat{\delta_k}(x)$ on suurin.

Tapauksessa jossa kullakin havainnolla $X$ on $p$ ennustetta, eli $X = (X_1, X_2, \dots, X_p)$ oletetaan että havainnot riippuvat moniarvo normaalijakaumasta $X \sim N(\mu_k, \pmb{\Sigma})$. Tässä $\mu_k$ on luokan $k$ yhteinen odotusarvo $E(X)$, ja $\pmb{\Sigma}$ on havainnon $X$ $p \times p$ kokoinen kovarianssimatriisi $Cov(X)$. Kovarianssimatriisi on kaikille havainnoille yhteinen arvo. Moniarvo normaalijakauman tiheysfunktio saa seuraavan muodon.

\begin{equation} \label{eq:multivariate}
    f(k) = \frac{1}{(2\pi)^{p/2} |\pmb{\Sigma}|^{1/2}} \exp{-\frac{1}{2} (x - \mu)^T \pmb{\Sigma}^{-1} (x - \mu)}
\end{equation}

Samalla tavalla kuin yksittäisellä ennusteella $p$, sijoitetaan kaava \ref{eq:multivariate} tiheysfunktion paikalle $f_k = (X = x)$ Bayesin kaavaan \ref{eq:bayes}, ja otetaan tästä kaavasta logaritmi, jolloin saavutetaan luokittelun päättävä kaava.

\begin{equation}
    \delta_k(x) = x^T \pmb{\Sigma}^{-1} \mu_k - \frac{1}{2} \mu_k^T \pmb{\Sigma}^{-1} \mu_k + \log \pi_k
\end{equation}

Arvot $\mu_1, \dots, \mu_K$, $\pi_1, \dots, \pi_K$ korvataan arvioilla \ref{eq:estimate-mu} ja \ref{eq:estimate-pi} edellisessä kaavassa ja kovarianssin $\pmb{\Sigma}$ löytämiseen, kaavan arvion $\hat{\delta}_k$ selvittämiseksi. Päälle näkyvästä monimutkaisuudestaan huolimatta LDA:n vektori-versiokin riippuu vain arvojensa lineaarisesta suhteesta.

LDA:n on toimiva approksimaatio Bayesin luokittelijasta\cite{james2013ISLR}. Sen suurimpana rajoituksena on oletus havaintojen tiheyden funktiosta. Jos havainnot eivät seuraa normaalijakaumaa ovat LDA:n antamat ennusteet tarkkuudeltaan varsin rajallisia.

Opetuksessa on LDA:ta käytetty opiskelijoiden suoriutumisen ennustamiseen tenttikysymyksien perusteella\cite{7265316} IT-aiheisella kurssilla. 

Valitsin LDA:n vertailtavaksi algoritmiksi koska se on Bayes-luokittelijan approksimaatio. Se tarjoaa mahdollisuuden vertailla kahta approksimoitua Bayes luokittelijaa, naive Bayes- ja LDA-luokittelijaa.


\subsection{Linear regression}

Lineaarinen regressio on yksinkertainen ohjatun oppimisen (\ref{term:supervised}) sovellus\cite{james2013ISLR}. Se on ollut käytössä pitkään ja se on edelleen laajasti käytetty tilastollinen menetelmä. Sen katsotaan olevan hyvä lähtökohta muiden koneoppimismenetelmien ymmärtämiseen. Iästään huolimatta lineaarinen regressio pystyy vastaamaan varsin joustavasti ilmiön yksittäisten ominaisuuksien välisiin kysymyksiin. 

Yksinkertainen lineaarinen regressio olettaa luokan Y ja havainnon X välillä olevan lineaarinen suhde. Tämä suhde voidaan ilmaista seuraavasti. 

\begin{equation} \label{eq:1}
    Y = \beta_0 + \beta_1 X + \epsilon
\end{equation}

Yhtälössä $\epsilon$ kuvaa virhettä, jota ei yhtälöstä saada poistettua. Se syntyy arvoista, joita ei ole otettu tai pystytä ottamaan yhtälössä huomioon. Sitä voidaan ajatella satunnaisena kohinana jota aineistosta löytyy. Yhtälössä $\beta_0$ edustavaa leikkauspistettä, ja $\beta_1$ puolestaan on yhtälön kerroin. Ne ovat arvoja jotka yritetään opettaa funktiolle. Kun aineisto on saatavilla, voidaan yhtälöstä laskea arviot $\hat{\beta_0}$ ja $\hat{\beta_1}$. Näillä arvoilla voidaan antaa ennuste luokasta $\hat{y}$ annetule havainnolle $x$. Lineaarisessa regressiossa luokka $y$ on nominaalisen luokan sijasta ennuste mahdollisesta arvosta, eli se ei välttämättä ole kokonaisluku.

Yksinkertaisella lineaarisella regressiolla voidaan yrittää ennustaa luokkaa yksittäisen ennusteen perusteella. Usein ennusteita on useita, ja näin yksinkertaista lineaarista regressiota laajennetaan moni-lineaariseksi regressioksi (multiple linear regression) seuraavasti.

\begin{equation} \label{eq:2}
    Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p + \epsilon
\end{equation}

Tässä $p$ kuvaa valittujen ennusteiden määrää, numeroidut syötteet $X_1\dots p$ kuvaavat kutakin valittua ennustetta, joilla jokaisella on oma kertoimensa $\beta_1\dots p$.

Lineaarisella regressiolla saadaan nopeasti aikaiseksi suuntaa antavaa tietoa aineiston ominaisuuksista. Onko esimerkiksi havainnon ja luokan välinen suhde lineaarinen, tai kuinka vahva havainnon ja luokan välinen suhde on. Vastaukset ovat kuitenkin vain suuntaa antavia. Tarkempina heikkouksina lineaariselle regressiolle mainitaan että sille ei ole luontevaa tapaa käsitellä havaintojen kvalitatiivisia, eli laadullisia ennusteita\cite{james2013ISLR}. 

Akateemisen suoritumisen ennustamisessa lineaariset mallit, joihin lineaarinen regressio kuuluu, ovat käytetyimpiä. Lineaaristen mallien osuus käytetyistä ennustamisen menetelmistä oli vuonna 2018 31\%\cite{hellas2018predicting}. Lineaarista regressiota käyttivät muun muassa Carter ym. \cite{carter2015normalized} sekä Watson ym. \cite{watson2013predicting}.

Valitsin lineaarisen regression yhdeksi menetelmistä sen yksinkertaisuuden ja laajan käytön vuoksi. Yksinkertaisena mallina se tarjonnee jonkinlaisen vertailukohdan muita koneoppimismalleja soveltaessa.


\subsection{Support Vector Machine}

Tukivektorikone on ohjatun oppimisen menetelmä joka pyrkii jakamaan havaintoavaruuden kahteen osaan. Se laajentaa tukivektoriluokittelijaa mahdollistamalla epälineaarisen luokittelun kahden luokan välillä\cite{james2013ISLR}.

Tukivektorikone saa syötteekseen $n \times p$ kokoisen matriisin $\textbf{X}$, jossa on $p$-ennustetta, ja $n$-syötettä. Havaintojen luokat $y_1, \dots, y_n \in \{-1, 1\}$ ovat binäärisiä, joissa $-1$ ja $1$ ovat mahdollisia ennustettavia luokkia. 

Tukivektoriluokittelijan tavoin tukivektorikone pyrkii etsimään kahden luokan välisen rajan eli hypertason (hyperplane), ja saamaan mahdollisimman leveän marginaalin $M$ eri luokkiin kuuluvien havaintojen välille. Kullakin havainnolla $x_i$ on löysäysparametri (slack variable) $\epsilon_i$, joka kertoo havainnon sijainnin marginaaliin ja hypertasoon nähden seuraavasti. 

\begin{gather}
    \epsilon_i = 0\text{, niin havainto $x_i$ on oikealla puolella marginaalia}\\
    \epsilon_i > 0\text{, niin havainto $x_i$ on väärällä puolella marginaalia}\\
    \epsilon_i > 1\text{, niin havainto $x_i$ on väärällä puolella hypertasoa}
\end{gather}

Vektorit (eli havainnot) jotka ovat marginaalin sisällä tai ovat hypertason väärällä puolella, ovat nimeltään tukivektoreita. Sallittujen löysäysparametrien summaa määrää viritysparametri $C$, joka käytännössä valitaan ristivalidoinnilla (cross-validation). Löysäysparametrien summa $\sum^n_{i=1} \epsilon_i$ ei ylitä viritysparametria $C$. Viritysparametri säätelee tukivektoriluokittelijan ja tukivektorikoneen vinouma-varianssi tasapainoa (bias-variance trade-off). Siinä missä tukivektoriluokittelijaa käytetään kun havaintoavaruus on lineaarisesti jaettavissa, on tukivektorikone laajennettavissa muunkin muotoisilla funktioilla. Yleisesti tukivektorikone on ilmaistavissa seuraavasti.

\begin{equation}
    f(x) = \beta_0 + \sum_{i \in \textbf{S}} \alpha_i K(x, x_i)
\end{equation}

Jossa $\beta_0$ ilmaisee leikkauspistettä, $\textbf{S}$ sisältää havaintojen indeksit jotka ovat tukivektoreita, $\alpha_i$ on havainnon $x_i$ kerroin. Funktio $K$ on tukivektorikoneen ydinfunktio (kernel function). Tukivektorikoneen ydinfunktioksi voi asetella muun muassa polynomisen funktion, radiaalisen funktion tai tukivektoriluokittelijan lineaarisen funktion.

\begin{align}
    K(x_i, x_{i'}) &= \sum^p_{j=1} x_{i, j} x_{i', j} \text{ Lineaarinen ydinfunktio}\\
    K(x_i, x_{i'}) &= (1 + \sum^p_{j=1} x_{i, j} x_{i', j} )^d \text{ Polynominen funktio}\\
    K(x_i, x_{i'}) &= \exp{-\gamma \sum^p_{j=1}( x_{i, j} - x_{i', j} )^2} \text{ Radiaalinen funktio}
\end{align}

Parametri $p$ kertoo havaintoavaruuden ennusteiden määrän. Polynomisessa funktiossa parametri $d$ on polynomisen funktion valittu aste. Radiaalisen funktion $\gamma$ on positiivinen vakio.

Ydin-funktioiden voimin tukivektorikoneet ovat laskennallisesti yksinkertaisia, ja pystyvät käsittelemään moniulotteista (tai moniennusteista) dataa. Lisäksi tukivektorikoneen kouluttaminen on varsin muistitehokasta koska ainoastaan tukivektorit, eli havainnot jotka ovat marginaalin sisäpuolella tai hypertason väärällä puolella osallistuvat tukivektorikoneen oppimiseen. 

Kuten lineaariregressiossa, tukivektorikone ei tarjoa todennäköisyyksiä luokkien ennustamisen tueksi. Datasta riippuen ydin-funktion valitseminen voi olla haastavaa, varsinkin datassa jossa on rajusti kohinaa. Suuren kohinan määrän läsnäollessa tukivektorikone saattaa ylisovittua kohinaa myötäillen, rampauttaen tukivektorikoneen suoriutumista.

Opetuksen kontekstissa Kentli ym. \cite{kentli2011svm} pyrkivät ennustamaan tekniikan alan kurssin opiskelijoiden suoriutumista tukivektorikoneen avulla. Lagus ym. \cite{lagus2018transfer} tekivät vastaavia ennusteita ohjelmointikurssilla. Artikkeli\cite{lagus2018transfer} tutki transfer learning-koneoppimismallien suoritumista, jossa tukivektorikone oli verrokkina. Tukivektorikoneet luokittelivat kunnioitettavalla tarkkuudella opiskelijat, jotka pääsivät kurssista läpi. Ennustetarkkuuksien keskiarvot vaihtelivat kurssien edetessä aina 82\% ja 87\% prosentin väliltä.

Tukivektorikone on lineaariregression jälkeen luonteva jatke. Se on hyvin toteutettavissa ja siitä on olemassa olevia toteutuksia. Tukivektorikone on hyvä yleistämään aineistoa ja pystyy antamaan hyviä ennusteita yksinkertaisuuteensa nähden.


\subsection{Random Forest}

Random forest-menetelmä on kokoelma päättelypuita, ja on laajennus pussittamisesta (bagging)\cite{james2013ISLR} joka puolestaan perustuu bootstarpping-menetelmälle. 

Pussittamisen ajatuksena on tehdä useita satunnisia otoksia aineistosta. Tuotettu otos on alkuperäisen aineiston kokoinen. Kun aineistosta tehdään satunnaisia otoksia, voi syöte esiintyä useamman kerran pussitetussa aineistossa, ja osa taas voi jäädä otoksen ulkopuolelle. Aineiston ulkopuolisia syötteitä, eli "pussin ulkuopuolisia"  (out-of-bag) havaintoja hyödynnetään tuotetun mallin virheen arvioimiseen. Pussittamisessa tämä satunnainen otos tehdään $B$-kertaa, ja jokaiselle aineisto-otokselle tehdään oma päättelypuu. Regressio-ongelmassa päättelypuut antavat oman arvionsa, ja näistä arvioista lasketaan keskiarvo ennusteeksi.

\begin{equation}
    \hat{f}_{bag}(x) = \frac{1}{B} \sum^B_{b=1} \hat{f}^{*b}(x)
\end{equation}

Jos kyseessä on luokitteluongelma, saadaan luokan ennuste puiden enemmistöäänellä.\cite{james2013ISLR} 

Pussien määrä $B$:n kasvattaminen ei lisää ennusteiden ylisovittamista\cite{james2013ISLR}. Usein pussien määrän $B$ valinta tapahtuu siten, että sitä kasvatetaan kunnes luokitteluvirhe tasaantuu. 

Verrattuna yksittäiseen päättelypuuhun pussittaminen ennustusmenetelmänä on paljon tarkempi. Pussittamisen ongelmana on sama kuin yksittäisellä päätteylypuulla, eli syötteen korreloivat- ja vahvemmat ennusteet. Jos yksittäisellä ennusteella on vahva painoarvo luokittelussa, näyttävät pussittamisen päättelypuut keskenään samanlaisilta. Vastaavanlainen ongelma ilmenee korreloivissa ennusteissa luoden toistuvia rakenteita päättelypuissa.

Random forest ratkaisee ongelmaa vaikuttamalla logiikkaan, että millä valitaan kunkin puun haaran merkitsevä syötteen ennuste. Sen sijaan että syötteen jokaista ennustetta harkitaan kunkin haaran jakavaksi tekijäksi, valitaan jakava ennuste vain satunnaisen $m$-kappaleen joukosta. Lukumäärän $m$ määrittelee usein $m \approx \sqrt{p}$, eli syötteiden ennusteiden määrän määrän neliöjuuri. Näin random forest dekorreloi syötteiden ennusteita, ja saadaan suurempaa variaatiota luotujen päättelypuiden välille\cite{james2013ISLR}.

Ytimessään random forest on kokoelma päättelypuita. Sen ennusteet ovat huomattavasti merkittävästi varrattuna yksittäiseen päättelypuuhun\cite{james2013ISLR}. Koska päättelypuita on kokoelmassa useita ja satunnaisuus on olennainen osa mallin rakentamista, välttää random forest hyvin ylisovittamista\cite{james2013ISLR}. 

Usean päättelypuun käytön vuoksi random forest kuitenkin menettää yhden päättelypuun suurimmista eduista, joka on selkeä tulkittavuus\cite{james2013ISLR}. Päättelypuussa tuloksen tulkitseminen on yksinkertaista, sillä jokaista tulosta edustaa yksittäinen puun "lehti". Jokaisella lehdellä on selkeä reitti ja solmut, joita kautta kyseiseen lehteen on päädytty. Tämän sijasta random forest käyttää jokaisen puunsa antamaa ennustetta, joten ei tulos ole enään yhtä helposti luettavissa.

Opetukessa random forest on ollut mukana ennustamassa muun muassa hyvin ja heikosti suoriutuvia ohjelmointi-opiskelijoita. Yleisesti sitä on tarkasteltu muiden koneoppimismenetelmien rinnalla\cite{Ahadi:2015:EML:2787622.2787717}. Lisäksi se on ollut vertailussa tutkimuksessa transfer learning-menetelmän soveltuvuudesta samaan kontekstiin\cite{lagus2018transfer}. Molemmissa artikkeleissa random forest toimii poikkeuksellisella tarkkuudella.

Valitsin random forestin mukaan vertailuun koska se on mainittu erikseen ohjelmointiopetuksen kontekstissa. Haluan päästä näkemään saavutanko random forest-menetelmällä sen aiemman havaitun tarkkuuden.


\chapter{SQL-kurssin oppimenestyksen ennustamisen toteutus}

\section{Ohjelmakoodi}


\section{Prosessi, haasteet, yms.}


\section{Tulokset}


\chapter{Yhteenveto\label{chapter:Yhteenveto}}

It is good to conclude with some insightful discussion. 

% STEP 5:
% Uncomment the following lines and set your .bib file and desired bibliography style
% to make a bibliography with BibTeX.
% Alternatively you can use the thebibliography environment if you want to add all
% references by hand.

\cleardoublepage %fixes the position of bibliography in bookmarks
\phantomsection

\addcontentsline{toc}{chapter}{\bibname} % This lines adds the bibliography to the ToC
\bibliographystyle{abbrv} % numbering alphabetic order
\bibliography{bibliography}

\begin{appendices}
\myappendixtitle

\chapter{Code example\label{appendix:code}}
Program code can be added as appendix:
\begin{verbatim}
#!/bin/bash          
text="Hello World!"
echo $text
\end{verbatim}

\end{appendices}

\end{document}
