\begin{document}

\begin{itemize}
    \item syntaktiset- ja semanttiset virheet harvinaisempia kuin loogiset virheet ja sekaannukset
    \item SQL on kuulunut yliopistotason opintoihin vuosikymmeniä
    \item tieteellinen näyttö aiheille jotka ovat opiskelijoille vaikeita, on tulkinnanvaraista
    \item tutkimus SQL:n opetuksesta keskittyy joko opinto-työkaluihin ja opiskelijoiden virheisiin SQL:ssä
    \item virheet jaettavissa neljään luokkaan, lähteen 11 mukaan
    \begin{itemize}
        \item complication: eivät vaikuta tulostauluun
        \item logical error: vaikuttaa tulostauluun joka vaikuttaa tulostauluun. Näille tauluille on olemassa pätevä kysyntää
        \begin{itemize}
            \item operaattorivirhe LOG-1
            \item JOIN virhe LOG-2
            \item sisennysvirhe LOG-3
            \item määritelmävirhe LOG-4
            \item projektiovirhe LOG-5
            \item funktiovirhe LOG-6
            \item pakko tietää kysyntä/tarkoitus
        \end{itemize}
        \item semanttinen virhe: vaikuttaa tulostauluun, jolle ei ole pätevää kysyntää
        \begin{itemize}
            \item epäjohdonmukainen määritelmä SEM-1
            \item epäjohdonmukainen JOIN SEM-2
            \item puuttuva JOIN SEM-3
            \item toistuvia rivejä SEM-4
            \item tarpeeton sarake SEM-5
            \item ilmeinen katsomatta kysyntää/tarkoitusta
        \end{itemize}
        \item syntaktinen virhe: palauttaa virheviestin tulostaulun sijasta
        \begin{itemize}
            \item epäselvä tietokanta objekti SYN-1
            \item määrittelemätön tietokantaobjekti SYN-2
            \item yhteensopimaton tietotyyppi SYN-3
            \item laiton ryhmittely(aggregation) funktion asettelu SYN-4
            \item laiton tai riittämätön ryhmittely SYN-5
            \item yleinen syntaksivirhe SYN-6
        \end{itemize}
    \end{itemize}
    \item pysyvimmät virheet
    \begin{itemize}
        \item laiton tai riittämätön ryhmittely SYN-5
        \item yleinen syntaksivirhe SYN-6
        \item epäjohdonmukainen määritelmä SEM-1
        \item epäjohdonmuainen JOIN SEM-2
        \item puuttuva JOIN SEM-3
        \item määritelmävirhe LOG-4
        \item projektiovirhe LOG-6
    \end{itemize}
    \item kaikkien kyselyiden kesken yleisimpiä ovat
    \begin{itemize}
        \item yleinen syntaksivirhe SYN-6
        \item määrittelemätön tietokantaobjekti SYN-2
        \item laiton tai riittämätön ryhmittely SYN-5
    \end{itemize}
    \item loogiset virheet ovat vaikeita ratkaista
    \item viite 10 ehdottaa että loogiset virheet liittyvät lyhytaikaiseen muistiin, ja ajatuksenkulusta mikä liittynee ajatusprosessiin luonnollisenkielenkääntämisestä SQL:n
    \item sekaannukset (complications) ovat yleisiä, mutta yleensä korjaantuvat kyselyn kehittyessä
    \item erilaiset kyselykonseptit tuovat erilaisia virheitä by design
    \begin{itemize}
        \item esimerkiksi kokoamisfunktiot tuovat funktiovirheitä
    \end{itemize}
    \item lienee johdonmukaista olettaa että opettajien ja tutkijoiden pitäisi keskittyä virheisiin jotka ovat yleisiä ja pysyviä
    \item virheelliset datatietotyyppivirheet vähenivät kurssin edetessä
    \item kokoamis (aggregate) funktiot voat vaikeita
    \item kyselyt, jotka vaativat viittä tai kuutta SQL ehtoa (clauses) ovat vaikeita. Yleensä kyselyissä on kolmesta neljään ehtoa
    \item epäjohdonmukaiset määritelmät olivat yleisiä: jokainen kysely sisältää niitä
    \item moni-tauluiset kyselyt olivat yleisiä siellä missä niitä käytettiin.
    \item loogiset virheet ja sekaannukset ovat pysyvämpiä verrattuna syntaktisiin ja semanttisiin virheisiin
    \item funktiovirheet olivat yleisiä tehtävissä tietyillä kyselykonsepteilla
    \item säilyvimmät virheet olivat määritelmä ja projektiovirheet kyselykonsepteista huolimatta
\end{itemize}

\chapter{Muistiinpanoja}

\section{Muistiinpanoja: The Normalized Programming State Model}

Oleellinen termi: explained variance
\begin{itemize}
    \item \url{https://en.m.wikipedia.org/wiki/Explained\_variation}
    \item \url{http://www.csun.edu/~mr31841/documents/Varitionandpredictionintervals.pdf}
\end{itemize}

\subsection{tutkimuskysymys}

\begin{itemize}
    \item Miten eri tavoin eri ympäristöt, kielet ja ohjelmointiympäristöt vaikuttavat Error Quotient\cite{jadud2006methods}- ja Watwin\cite{watson2014no} piste-asteikon ennustaviin kykyihin?
    \item Kuinka hyvin kokonaisvaltaisempi malli ennustaa suoritusta?
\end{itemize}


\subsection{tutkimustulokset}

Normalized Programming State Model eli NPSM, suoriutui tutkimuksen\cite{carter2015normalized} ympäristössä Error Qutient- ja Watwinin piste-asteikkoa paremmin.

\begin{itemize}
    \item RQ1
        \begin{itemize}
            \item rajua vaihtelua mittauksissa Error Quotient ja Watwin-asteikossa, 6.1:1:1
            \begin{itemize}
                \item Tämän kokeen asetelmassa suurempi arvosanapainotus tehtäville, 6.1:2:5
                \item edellämainitut tukeutuvat vahvemmin ohjelmointiympäristön virheviesteihin ja tukeen, ja Javan parempiin virheviesteihin. Verrattuna tämän tutkimuksen kieleen C++:n, 6.1:3:3
                \item Molemmat rankaisevat toistuvista virheviesteistä, 6.1:3:9
                \begin{itemize}
                    \item C++:n virheviestit voivat sisältää samoja virkkeitä eri virheissä -> false positive
                \end{itemize}
            \end{itemize}
            \item Tutkimuksessa toistui aikaisemmat ilmiöt: Error quotient toimii parhaiten pienemmillä tietolähteillä, ja Watwin suuremmilla tietolähteillä, 6.1:5:2
            \item Watwin-asteikon "variance explained" toistuu muissa tutkimuksissa, missä taas Error Quotient:n vastaava arvo ei toistu, 6.1:5:7
            \item Kaikki mallit vaativat lisätutkimuksia eri ympäristöissä, 6.1:5:13
        \end{itemize}
    \item RQ2
    \begin{itemize}
        \item NPSM päihitti mallit jotka keskittyivät vain kääntämis-käyttäytymiseen (compilation), 6.2:1
        \begin{itemize}
            \item Yksittäisissä tehtävissä Watwin asteikkoon nähden nelinkertaiset tulokset varianssin selitettävyydessä, ja Error Quotient:iin nähden prosentin verran
            \item Tehtävä-arvosanojen keskiarvossa 4x Watwin-asteikkoon, ja 6x Error Quotient asteikkoon nähden
            \item Loppuarvosanoijen ennustettavuudessa, 3x Watwin-asteikkoon, ja 12x Error Quotient nähden
        \end{itemize}
        \item Ajaminen semanttisesti väärää ohjelmaa, ja semanttisesti tuntematonta sovellusta edistivät onnistumista, 6.2:2:2
        \item tuntematon tila (eli oletustila ennen ensimmäistä ajoa) ja syntaktisesti väärän ohjelman ajaminen tekivät hallaa onnistumiselle, 6.2:2:6
        \item vetivät johtopäätöksen että sovelluksen ajaminen, oli kyseessä oikea ratkaisu tai ei, vaikuttaa olevan onnistuva ohjelmointi lähestymistapa, 6.2:2:11
        \item koodin kirjoittaminen ilman ajamista isoissa paloissa, päinvastoin, 6.2:2:13
    \end{itemize}
\end{itemize} 


\subsection{muistiinpanoja}

\begin{itemize}
    \item Ennusteet auttavat opettajia tunnistamaan riskirajoilla olevia opiskelijoita, ja parantamaan opetusmenetelmiä\cite{carter2015normalized}, Abstract:1:3
    \item Error Quotient asteikko\cite{jadud2006methods} ja Watwinin pisteasteikko\cite{watson2014no} ovat saavuttaneet menestystä tarkastellen ainoastaan opiskelijoiden kääntämis-yrityksiä(compilation), Abstract:1:6
    \item dataa ilmeisesti kerätty oppimisprosessin aikana striimaten\cite{carter2015normalized}, Introduction:1:1, 2. Background and related work:2:1
        \begin{itemize}
            \item NPSM keräsi 11 muuttujaa, joista yksi on käytetty aktiivinen aika, 3.2:2:8
            \item näistä kymmenen normalisoitiin tehtävään käytettyyn aikaan, 3.2:1:7
        \end{itemize}
    \item menetelmät ovat koulutuksellinen (educational) datan louhinta ja oppimis analytiikka
    \begin{itemize}
        \item Lue ainakin sisälysluettelot viitteistä 3 ja 24
    \end{itemize}
    \item Ohjelmointi-opetukseen kätevää lisätä data-louhintaa, koska tavoitteena on parantaa opiskelijoiden toistoa, Introduction:2:4
    \item ennusteita tehtiin
    \begin{itemize}
        \item yksittäisten tehtävänantojen arvosanoihin, 4.3.1
        \begin{itemize}
            \item selittävimmät oli tuntematon eli aloitustila, syntaksi virheiden kanssa painimenn ja ohjelman ajaminen ilman koodin korjausta (debugging), 4.3.2:3:3
        \end{itemize}
        \item tehtävien arvosanojen keskiarvoon, 4.3.2
        \begin{itemize}
            \item myöhäinen aloitusvaihe korreloi negatiivisesti, 4.3.2:3:4
            \item syntaksivirheiden kanssa pitkään olo korreloi negatiivisesti, 4.3.2:3:4
        \end{itemize}
        \item Loppuarvosanan enenustaminen, 4.3.3
        \begin{itemize}
            \item tarkemmin, yritettiin selittää varianssi loppuarvosanoissa, 4.3.3:1:1
        \end{itemize}
    \end{itemize}
    \item Mielenkiintoinen huomio optimaalisesta otoskoosta kappaaleessa 5:2:2
    \item Kurssin aikana ennustamista kappaleessa 5
    \item multivariate regression, 5.2:1:1
    \item linear regression, 5.3:3:3
    \item Mallista rakennetut ennustavat funktiot antavat käytettävissä olevia tuloksia, 5.3:3:12
    \item Watwin-asteikko ja Error Quotient perustuvat NPSM mallin vähiten painotettuun merkittävään arvoon: "muokkaa syntaktisesti väärää koodia, edellinen ajo onnistunut", 6.2:3:1
    \begin{itemize}
        \item Lineaari regression ajaminen pelkästään tällä arvolla, NU:lla, "explains more variance" kuin kumpikaan asteikoista
        \begin{itemize}
            \item Vahva epäilys että mittaukset ohjelmointikäytökseen ajamis-käytöksen lisäksi suoriutuvat hyvin
        \end{itemize}
    \end{itemize}
\end{itemize}

\section{Muistiinpanoja: Methods and Tools for Exploring Novice Compilation Behaviour\cite{jadud2006methods}}

Skouppi: Ohjelmoinit kurssimenestyksen ennustaminen

\begin{itemize}
    \item Tarkastelee kääntämis-käyttäytymistä, (compilation behaviour)
    \begin{itemize}
        \item Tarkastelee siis kirjoitettavan koodin syntaktista tilaa
    \end{itemize}
    \item Java kurssille tehty tutkimus
    \begin{itemize}
        \item BlueJ-ympäristö
    \end{itemize}
    \item Kysymyksiä
    \begin{itemize}
        \item Suuria muutoksia session aikana?
        \item Pitkä-kestoisia muutoksia?
        \item ongelmallisia syntaksi-virheitä?
        \item minne muutokset sijoittuivat?
    \end{itemize}
    \item Valitut muuttujat:
    \begin{itemize}
        \item ErrType
        \item Delta-T: ajojen välinen aika
        \item Delta-Ch: muutettujen merkkien määrä
        \item Location: sijainti koodissa
    \end{itemize}
    \item Error Quotient
    \begin{itemize}
        \item Collate: parit tapahtumien välillä sessiossa
        \item Calculate: algoritmin mukainen pisteytys kunkin tapahtuman välillä
        \begin{itemize}
            \item Jos molemmat ovat virheellisiä -> pisteet kasvaa
        \end{itemize}
        \item Normalize: normalisoidaan pistemäärä jakamalla tulos yhdellätoista. Yksitoista on mahdollisten tilojen summa
        \item Average: keskiarvo parien pisteistä sessiossa -> ERROR QUOTIENT
    \end{itemize}
    \item on korrelaatiota opiskelijan EQ:n, loppuarvosanana ja tehtävien arvosanojen keskiarvon välillä on korrelaatiota
    \begin{itemize}
        \item ei kuitenkaa sovi kovinkaan tarkasti: EQ lienee varsin kapea mittari
        \item tarkempi sovitus EQ:n ja loppuarvosanan välillä, edelleen epätarkka
    \end{itemize}
    \item eivät voi tehdä vahvoja väitteitä, että EQ:ta voisi käyttää ennustavana asteikkona tentti-asteikkoon
    \begin{itemize}
        \item Liikaa puuttuvaa tietoa
    \end{itemize}
    \item Paperissa ei mainita mihinkään malliin sovittamista
\end{itemize}


\section{Watson-Score artikkelin muistiinpanoja\cite{watson2013predicting}}

\begin{itemize}
    \item Halutaan tunnistaa vaikeuksissa olevat opiskelijat mahdollisimman varhaisessa vaiheessa
    \begin{itemize}
        \item varhainen opettajan puuttuminen
    \end{itemize}
    \item otos: 45 oppilasta
    \begin{itemize}
        \item yliopiston johdatus ohjelmointiin-kursi
        \item koodi-snapshot jokaisen ajon yhteydessä
    \end{itemize}
    \item pisteytys
    \begin{itemize}
        \item rangaistaan ajasta, joka kuluu tietyn ongelman ratkaisemiseen
        \item verrokkina muut opiskelijat
        \item normalisoituna arvo nollan ja yhden välillä
    \end{itemize}
    \item Käytännösssä kyseessä on tilakone: tarkastellaan perättäisten tilojen vuorovaikutusta
    \item parit muodostettu perättäisistä ajoista ja tiloista tiedosto kohtaisesti. Kronologisessa järjestyksessä hukkuu tieto useamman tiedoston välisistä tiloista
    \item identtiset, perättäiset tilat poistettu IDE:n ominaisuuden vuoksi
    \item poisto-korjaukset suodatettu
    \item virheviestien yleistys
    \item työaikaarviointiin liittyi ongelmia, koska parit on muodostettu tiedostokohtaisesti. Aika käytetty kuhunkin tiedostoon arvioitu koko tapahtumajonosta
    \item soveltuvat ennustavat ominaisuudet
    \begin{itemize}
        \item peräkkäiset virheet olivat
        \begin{itemize}
            \item virheellisiä yleensä
            \item virhetyypit ovat samanlaisia
            \item virhetyypit erilaiset
            \item sama virhesijainti
        \end{itemize}
        \item keskiarvoinen virheen suoritus/selvitysaika. Huomioitiin että eri virheet vaativat eri aikamäärän
        \begin{itemize}
            \item Jälleen yleisen virhetyypin mukaan! Vertailu tapahtuu yleisen virhetyypin mukaan ja vertaillen muihin opiskelijoihin.
        \end{itemize}
        \item rangaistus-pisteet valittiin brute-force haulla, reilun pisteytyksen saavuttamiseksi. Testattiin cross-validation-menetelmällä
    \end{itemize}
    \item arviointi
    \begin{itemize}
        \item lineaari-regresio
        \begin{itemize}
            \item opiskelijoiden Watwin-pisteytys itsenäinen muuttuja
            \item opiskelijoiden kurssin tehtävien pisteytys koko kurssin ajalta
        \end{itemize} 
        \item Harkittiin luokittelijaa kyseisen yliopiston arvosana-asteikon mukaan
        \item on lineaarinen relaatio Watwin-pisteytyksen ja suorituksen välillä, ilman merkittäviä poikkeavuuksia
    \end{itemize}
\end{itemize}

\chapter{Berginin ohjelmointiennustamis-artikkelin muistiinpanot}

Berginin artikkeli koneoppimisen käyttämisestä\cite{bergin2015using}

\begin{itemize}
    \item Motivaatio
    \begin{itemize}
        \item ohjelmoinnin oppimisessa vaikeuksia: korkea pudotusaste
        \item vaikeuksissa olevan opiskelijan tunnistaminen on vaikeaa ajoissa suuresta opiskelija määrästä johtuen.
        \begin{itemize}
            \item ajoitus tärkeä! Liian myöhään, niin opiskelija ei voi jättäytyä pois, tai ohjaajan tuki on myöhässä
        \end{itemize}
        \item edeltävissä tutkimuksissa ongelmia
        \begin{itemize}
            \item tarkat parametrit: biased findings
            \item validaatio-tutkimuksista puuteta
            \item parhaimmissa lähinnä tilastollisia menetelmiä
            \begin{itemize}
                \item rajoittuneet näiden mallien oletuksiin -> ei välttämättä parhain malli
            \end{itemize}
        \end{itemize}
    \end{itemize}
    \item Principal Component Analysis (PCA) ulottuvuuksien pienentämiseen
    \item paperin tarkoituksena on ENNUSTAA ennen kurssin alkua, että miten kurssi etenee
    \begin{itemize}
        \item Tarkemmat kuvaukset arvoista löytyy artikkelin neljännestä viitteestä
        \item etuna on että ei tarvita tietoa kurssityöstä, saati tarkkaa mallia tällaisen tiedon käyttämiseen
    \end{itemize}
    \item valittujen mallien vaatimuksena on että ne ovat toteutettavissa!
    \item testatut koneoppimis-algoritmit
    \begin{itemize}
        \item logistic regression
        \item k-nearest neighbor
        \item backpropagation
        \item C4.5
        \begin{itemize}
            \item Päättelypuu-algoritmi
        \end{itemize}
        \item naive Bayes
        \item support vector machine
    \end{itemize}
    \item Naive Bayes vahvin tarkkuudessa ja herkkyydessä (accuracy, sensitivity)
\end{itemize}

\begin{itemize}
    \item e-oppiminen on ollut suosittu tutkimuksen kohde vuodesta 2000 eteenpäin\cite{Brusilovsky:2010:LSP:1656255.1656257}
    \item opetusohjelmistojen tukijat toivovat siirtymistä passiivisesta ja tehottomasta lukemalla oppimisesta, aktiiviseen tekemällä oppimiseen\cite{Brusilovsky:2010:LSP:1656255.1656257}
    \item olemassa olevien työkalujen integroiminen ja personoiminen on ollut vähäistä teknisten vaikeuksien vuoksi
    \item opiskelijoiden etenemisen seuraaminen hankalaa olemassa olevissa työkaluissa
    \item integroidun järjestelmän on mahdollistettava työkalun käyttö ilman montaa kirjautumista
    \item integroidun järjestelmän on pystyttävä seuraamaan opiskelijoiden toimintoja (kaikista mukana olevista järjestelmistä) ja tallennettuna siten että muut järjestelmät voivat hyödyntää niitä
    \item integroidun järjestelmän on mahdollistettava opiskelijoiden tiedon päätteleminen heidän kirjatuista toiminnoistaan eri järjestelmissä
    \item käytetyt työkalut parantavat tehtäväpalautukisen arvosanoja
    \begin{itemize}
        \item ei kyselyä ryhmälle, joka ei käyttänyt työkalua
    \end{itemize}
    \item Työkalua suunnitellessa käyttötarkoituksen mukainen työkalun personointi on tärkeää: vahvistaa e-oppimisen hyötyjä. Muun muassa luonteva ohjelmistossa suunnistaminen on tärkeää
\end{itemize}


\begin{itemize}
    \item SQL on yksi välttämättömistä aiheista korkeakouluopetuksessa
    \item yksinkertaisen näköisen syntaksin vuoksi SQL:n koko tehon oppiminen voi olla hankalaa
    \item SQLator on vuonna 2004 käytössä ollut web-pohjainen interaktiivinen nettikäyttöliittymä SQL:n oppimiseen
    \item SQLator:n päätoimintona on kyselyjen arviointi, kuinka oiken kyselyn muodostus on
    \item SQLator tarjoaa ohjaajille mahdollisuuden luoda ja täyttää tietokanta kaavioita, ja antaa niihin liittyvän kokoelman SQL-kyselyitä
    \item e-oppiminen oli ainakin vuonna 2004 mielenkiintoa herättävä aihe akateemisessa maailmass a ja teollisuudessa
    \item e-oppimista harkitessa on tärkeää kysyä että onko teknologian käyttö pedagogisesti järkevää, ja opetuksellisesti arvokasta
    \item mielenkiintoa herättävä teknologia oikein käytettynä auttaa opiskelijoita saavuttamaan aiheen syväoppimista
    \item on olemassa useita menestyksestä nauttivia e-oppimis teknologioita
    \item e-oppimisen voi jakaa kolmeen luokkaan
    \begin{itemize}
        \item "management system"
        \item "collaborative learning"
        \item työkalut jotka kohdistavat tietyt oppimisaktiviteetit, esimerkiksi simulaattorit, interaktiiviset työkalut ja Multiple Choise Question-tietopankit
    \end{itemize}
    \item SQLator kuuluu kolmanteen luokkaan. On netti-oppimistyöalusta (online learning workbench)
    \item SQLator tarjoaa
    \begin{itemize}
        \item lyhyitä multimediakursseja, jotka esittelevät peruskonsepteja
        \item kokoelman tietokantoja joihin liittyy omia harjoituskyselyitä
        \item mahdollisuuden kirjoittaa ja suorittaa mitä tahansa SQL-kyselyitä annettuihin tietokantoihin
        \item pääominaisuutena kyvyn arvioida yritettyjä SQL-kyselyjä kysyttyihin harjoituskysymyksiin
        \item oppijalle mahdollisuuden kirjata muistiinpanoja omista yrityksistä, seurata yksilön etenemistä tila-raporteilla, ja ryhmän etenemistä tilastojen perusteella
        \item oppijalle mahdollisuuden antaa palautetta ja olla vuorovaikutuskessa suoraan opetus henkilökuntaan
    \end{itemize}
    \item ymmärrys siitä, mikä on opiskelijan käsitys oppimisesta, on tärkeää käyttäessä teknologia työkaluja fasilitoimaan oppimista. Tämä on tärkeää aina opettamisessa, mutta sitäkin tärkeämpää opiskelija-opettaja-kontaktin puuttuessa
    \item SQLator lähestyy tätä kohdistamalla oppijan huomion tuotteen sijasta itse prosessiin. Tämä tapahtuu koska SQLator sallii opiskelijan keskittymisen konseptin kehittymiseen sen sijaan että opiskelija pyrkii arvioimaan häneen kohdistuvia odotuksia.
    \item SQL on hyväksytyin ja laahasti käytetty kieli tietokantojen hallinnoimiseen
    \item SQL-komennot sisällyttävät datan määrittämisen, manipuloimisen ja hallinnoimisen
    \item SQL SELECT-komennon syntaksin yksinkertaisuus antaa helposti harhaanjohtavan kuvan yksinkertaisuudesta oppijoiden mielissä
    \item SQL on vahva kyselykieli, jolla voidaan luoda hyvin monimutkaisia kyselyitä
    \item SQL:n deklaratiivinen luonne on hankala monelle oppijalle: SQL vaatii oppijoita ajattelemaan kokelmissa askelten sijasta
    \item kokemus osoittaa SQL:n olevan vaikea ja monimutkainen kieli oppia. SQL:n laaja käyttö ja sovellettavuus 
    \item kokemukset osoittavat että paras tapa oppia SQL:a on tarjota hyvin ohjattuja harjoitus sessioita, ja oppia omista virheistä
    \begin{itemize}
        \item Yksi tapa saavuttaa: tehtäväkokoelma, jonka tarkastaa kokenut SQL-käyttäjä
        \begin{itemize}
            \item ongelmana tehtävien arvioiminen: monia tapoja kirjoittaa sama kysely -> tekee arvioimisesta aikaa vievää -> vaarantaa opiskelijoiden palautteen
            \item SQLator rakennettu tällä oletuksella: korvaa ihminen koneella
        \end{itemize}
    \end{itemize}
    
    \item kehitetty SQL kyselyjen arvioimisen laskennallisen monimutkaisuuden vuoksi
    \item kehitetty käytännön syistä: SQL:n laaja käyttö oppimisessa ja opetuksessa. Opetusta tapahtuu korkeakoulu opetuksessa sekä ammattilais koulutuskursseilla
    \item tärkein ominaisuus on SQLator Equivalence Engine, joka arvioi vastaako ehdotettu vastaus englanninkielistä ohjetta
    \item sisältää useita valittavia tietokantoja
    \item kuhunkin tietokantaan kuuluu satoja skenaarioita joissa on haluttua kyselyä kuvaavia ohjeita
    \item kukin skenaario voidaan kategorisoida eri ryhmiin monimutkaisuuden tai kontekstin mukaan
    \item esi-määritellyt kyselyt edustavat SQLator:n ydin-tietoa
    \item pääsy kaikkialta
    \item autentikointi kirjautumistunnuksilla, jotka määrittävät käyttäjän roolin
    \item opiskelijalla pääsy perusominaisuuksin. Opettajalla enemmän toimintoja, esimerkiksi opiskelijoiden valvominen. Admin ylläpitää järjestelmää, tietokantoja ja kyselyitä
    \begin{itemize}
        \item opisklija valitsee ja tututstuu tietokantaan
        \item opiskelija valitsee kyselyn, ja lähtee ratkaisemaan kyselyä
        \item SQLator arvioi kyselyn
        \begin{itemize}
            \item oikein: kirjataan ylös ja näkyy yhteenvetona opiskelijalla
            \item väärin: opiskelija voi yrittää kyselyä uudestaan
            \item ei saa ratkaistua: voi tarkkailla oikeaa ratkaisua
        \end{itemize}
    \end{itemize}
    \item tarjoaa interaktiivisen ympäristön, millä tutustua tietokantoihin ilman tehtävää/arviointia
    \item tarjoaa multimedia-opetusmateriaalia SQL:stä
    \item tarjoaa mahdollisuudet palautteen, jota opettajat tarkastelevat palvelusta tai sähköpostitse
    \item antaa hallinnan plagiarismista
    \begin{itemize}
        \item väheni, koska annetut kyselyt ovat satunnaisia
        \item helppo suorittaa tarkistuksia
    \end{itemize}
    \item tilastot lokitiedoista mahdollistavat opiskelutapojen analysoimisen
    \item käsityö väheni: merkkaaminen automaattista, ksysymykset suoraan ohjaajille
    \item vertailussa kahden vuoden tenttiarvosanat ennen ja jälkeen SQLator:n käyttöönoton
    \begin{itemize}
        \item tentin kriteerit eivät muuttuneet
        \item arvosanat paranivat
        \item ei kuitenkaan täysin pätevä vertailu: eri opiskelijaryhmät
    \end{itemize}
    \item vihjesystemi tuleva ominaisuus
\end{itemize}

\begin{itemize}
    \item Ahadi ym. \cite{Ahadi:2016:SSM:2839509.2844640}  käyttivät datana yli 160 000 SQL snäpshottia yli 2000 opiskelijalta kahdeksan vuoden ajalta
    \item Ahadi ym. \cite{Ahadi:2016:SSM:2839509.2844640} tekivät sääntö-pohjaisen luokittelijan jolla on kokonaistarkkuus 78\% enustaessa opiskelijan suoritusta
    \item parempi ymmärrys opiskelijoiden SQL virheistä ja väärinymmärryksistä tarjoaa mahdollisuuden tehdä parempaa oppimateriaalia ja opetusta
    \item SQL kielessä voi tehdä semanttisia ja syntaktisia virheitä
    \item yleensä virheitä tarkastelevat tutkimukset ovat keskittyneet semanttisiin virheisiin
    \item harvoin tutkimukset SQL työkaluista tarjoavat analyysia kerätystä datasta
    \item AsseSQL
    \item alustava (introductory) tietokanta-kurssi, suuri osa ohjelmissa Information Technology tai Software Engineering kandidaatti-tasolla
    \item joka lukukauden päätteeksi seitsemän kysymyksen tentti, joissa kirjoitettiin SQL SELECT-kyselyjä. Kukin kysymyksistä kattaa yhden olennaisen alueen. Kysymykset tarkistettiin ajamalla ne oikeassa tietokannassa ja luokittelemalla mahdolliset virheet tarkemmin käsin
    \item rakennettiin luokittelija luokittelemaan onnistuneet ja epäonnistuneet luokittelijat. Sai syötteenä tiedon syntaktisista virheistä, semanttisista virheistä ja yritysten määrän 480:lta oppilaalta. Luokittelija koulutettiin opiskelijoista joille annettiin sama identtinen kysymys.
    \item luokittelijana PART: sääntöpohjainen luokittelija, rakentaa osittaisen (partial) C4.5. Esittää parhaan lehden sääntönä. Hallitsee hyvin puuttuvat arvot ja tarjoaa selkeän selityksen generoiduista C4.5 iteraatioista
    \begin{itemize}
        \item koulutettiin otoksella, jossa on yhtämonta onnistunutta ja epänonnistunutta opiskelijaa
        \item N=480
        \item 10-kertainen cross-validation
        \item 77\% luokiteltiin oikein
        \item toistuvien piirteiden, ylisovittamisen välttämiseksi ja ennustustarkkuuden parantamiseksi tehtiin piirre-valintaa (feature selection)
        \begin{itemize}
            \item correlation-based feature subset selection:
            \begin{itemize}
                \item genetic search
                \item best first method
                \item greedy stepwise method
            \end{itemize}
            \item valittiin neljä piirrettä luokittelijan kouluttamiseen
            \begin{itemize}
                \item kuinka monta ryhmittelyvirhettä
                \item kuinka monta syntaksivirhettä
                \item kuinka monta semanttista virhettä
                \item yritysten kokonaislukumäärä
            \end{itemize}
        \end{itemize}
        \item PART generoi viisi sääntöä
    \end{itemize}
    \item usein jos opiskelija lopettaa yrittämisen, on kyseessä syntaksivirhe, jota opiskelija ei saa korjattua
    \item syntaktiset virheet yleisimpiä
    \item epäonnistuvilla opiskelijoilla on enemmän virheitä ylipäänsä, molempia syntaktisia ja semanttisia
    \item luokittelijan tutkimuskysymyksenä oli, mikä on sopiva määrä kamppailua on hyvä ennuset oikean vastauksen saamiseksi
    \item ryhmittelyvirhe kolmanneksi yleisin, lähes aina esiintyi WHERE-komennossa jos oli esiintyäkseen: todennäköisesti vakava väärinymmärrys
    \item määrittelemätön taulu kolmen yleisimmän syntaksivirheen joukossa. Tapahtuu kun useampi kuin yksi taulu, tai enemmän kun yksi SELECT-komento. 
    \begin{itemize}
        \item joko puuttuu ymmärrys halutun tiedon oikeasta sijainnista, tai taulun nimen väärin kirjoittaminen
    \end{itemize}
    \item koneoppimis-algoritmien tulokset ovat rajusti konteksti-riippuvaisia. Tarkkuus vaihteli 60\% ja 79\% välillä vaikka kyse olisi ollut samasta algoritmista ja samasta otoksesta
\end{itemize}

\begin{itemize}
    \item oleellinen osuus: hyperplane, eli hypertaso
    \begin{itemize}
        \item $p$-ulotteisessa avaruudessa jakava litteä $p-1$ ulotteinen taso
        \item $\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p = 0$ $p$-ulotteisessa avaruudessa
        \item jos $X = (X_1, X_2, \dots , X_p)^T$, niin X on hypertasolla
        \item vastaavasti jos $\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p > 0$, niin vektori $X$ on toisella puolella hypertasoa, ja päinvastoin
        \item jakaa avaruuden kahtia
    \end{itemize}
    \item separating hyperplane eli jakava hypertaso, jakaa avaruudessa olevat harjoitus-havainnot täydellisesti luokkiensa mukaan
    \item luokittely jakavalla hypertasolla:
    \begin{itemize}
        \item syöte on $n \times p$ kokoinen matriisi $\textbf{X}$, jossa on $p$-ulottuvuutta ja $n$-syötettä
        \item $x_1 = \begin{pmatrix}
            x_{1,1} & \\ 
            \vdots & \\ 
            x_{1,p}
        \end{pmatrix}, \dots , x_n = \begin{pmatrix}
            x_{n,1} &\\
            \vdots & \\
            x_{n,p}
        \end{pmatrix}$
        \item havainnot kuuluvat kahteen luokkaan: $y_1, \dots, y_n \in {-1, 1}$, jossa -1 ja 1 ovat mahdollisia luokkia
    \end{itemize}
    \item hypertason avulla saadaan maximal margin classifier: etsitään hypertaso joka on mahdollisimman kaukana harjoitus-havainnoista. Etäisyys-vektorit "tukevat" hypertasoa
    \begin{itemize}
        \item ylisovittaa ulottuvuuksien määrän ollessa suuri
        \item koska todellisessa datassa on harvinaista että data on eroteltavissa (separable), ei pelkkä maksimaalisen marginaalin luokittelija toimi
        \item yksittäinen havainto saattaa dramaattisesti kääntää hypertasoa
    \end{itemize}
    \item support vector classifier, tukivektoriluokittelija, myöskin soft margin classifier
    \begin{itemize}
        \item joustava yksittäisille havainnoille
        \item hyvä luokittelu suurimmalle osalle havainnoista
    \end{itemize}
    \item sallii havaintojen olevan väärällä marginaalin ja hypertason puolella
    \begin{itemize}
        \item $maksimoi_{\beta_0, \beta_1, \dots, \beta_p, \epsilon_1, \dots, \epsilon_n, M} M$
        \item riippuen $\sum^p_{j=1}\beta^2_j=1$
        \item $y_i(\beta_o + \beta_1 x_{i,1} + \beta_2 x_{i, 2} + \dots + \beta_p x_{i, p}) \geq M(1 - \epsilon_i)$
        \item $\epsilon_i \geq 0, \sum^n_{i=1} \epsilon_i \leq C$
        \item $C$ on positiivinen viritysparametri
        \begin{itemize}
            \item voidaan ajatella "budjettina", jolla määrällä on lupa loukata marginaalia tai hypertasoa
            \item jos $C = 0$, vastaa tukivektorikone maksimaalisen marginaalin luokittelijaa
            \item löysäysparametrien $\epsilon_i$ summa ei ylitä viritysparametria $C$
            \item marginaalin leveys $M$ laajenee viritysparametrin $C$ kasvaessa
            \item hallitsee vinouma-varianssi tasapainoa (bias-variance trade-off)
            \item $C$ on pieni: pieni vinouma ja korkea varianssi, ja päinvastoin
            \item käytännössä $C$ valitaan ristiin-validoinnin avulla (cross-validation)
        \end{itemize}
        \item $M$ on marginaalin leveys, jota pyritään saamaan mahdollisimman suureksi
        \item $\epsilon_1, \dots, \epsilon_n$: slack variable, löysäysparametreja, jotka sallivat havaintojen olevan marginaalin tai hyperparametrin väärällä puolella
        \begin{itemize}
            \item jos $\epsilon_i = 0$, niin havainto $i$ on oikella puolella marginaalia
            \item jos $\epsilon_i > 0$, niin havainto $i$ on väärällä puolella marginaalia, ja täten loukkaa (violates) marginaalia
            \item jos $\epsilon_i > 1$, niin havainto $i$ on väärällä puolella hypertasoa, ja täten loukkaa hypertasoa
        \end{itemize}
        \item kun edelliset vaiheet on ratkaistu, testihavainto $x^*$ luokitellaan hypertason mukaan: $f(x^*) = \beta_0 + \beta_1 x^*_1 + \dots + \beta_p x^*_p$
        \item havainnot marginaalin oikealla puolella eivät vaikuta tukivektorikoneeseen
        \item havainnot marginaalin sisällä tai hypertason väärällä puolella ovat tukivektoreita
        \item tukivektoriluokittelija käyttää lineaarista funktiota hypertason ja marginaalin määrittämiseen, joka ei aina todellisessa datassa toimi
        \item tukivektorikone on tukivektoriluokittelijan laajennus, joka laajentaa piirreavaruutta tietyllä tavalla hyödyntäen tietynlaista kerneliä (kernel)
        \item kernelien pääajatus on ottaa huomioon epälineaariset rajat luokkien välillä
        \item tukivektoriluokittelija voidaan esittää tukivektorikoneena seuraavasti:
        \begin{itemize}
            \item $f(x) = \beta_0 + \sum^n_{i=1} \alpha_i \langle x, x_i \rangle$
        \end{itemize}
        \item parametrien $\alpha_1, \dots, \alpha_n$ ja $\beta_0$ arvioimiseen tarvitaan vain syötteiden $\binom{n}{2}$ sisätulot $\langle x_i, x_{i'} \rangle$ kaikkien harjoitus-havaintojen väliltä
        \item jos kyseessä ei ole tukivektori, on kahden pisteen välinen sisätulo nolla. Näissä tapauksissa myös estimaatti $\alpha_i$ on nolla. Näin voidaan tarkentaa funktiota ryhmällä $S$, jossa on pisteiden indeksit jotka ovat tukivektoreita:
        \begin{itemize}
            \item $f(x) = \beta_0 + \sum_{i \in S} \alpha_i \langle x, x_i \rangle$
        \end{itemize}
        \item tukivektorikoneen sisätulot voidaan yleistää muotoon $K(x_i, x_{i'})$, jota kutsutaan kerneliksi
        \item tukivektorikone voidaan siis sanoa yleisesti seuraavasti:
        \begin{itemize}
            \item $f(x) = \beta_0 + \sum_{i \in S} \alpha_i K(x, x_i)$
            \item jossa funktio K on kerneli, joka voidaan vaihtaa dataan sopivaan funktioon
            \item kerneli voi olla esimerkiksi lineaarinen, radiaalinen tai polynominen
        \end{itemize}
    \end{itemize}
\end{itemize}

\begin{itemize}
    \item artikkeli \cite{rish2001empirical}
    \item Bayesian luokittelijat tarjoavat todennäköisyyden mahdollisesta luokasta
    \item tekemällä oletuksen/yksinkertaistuksen, että havaintojen piirteet ovat itsenäisiä, saadaan Naivé Bayes-luokittelija
    \item $P(\textbf{X} | C) = \Pi^n_{i=1} P(X_i|C)$
    \begin{itemize}
        \item $\textbf{X} = (X_1, \dots, X_n)$ eli havaintovektori
        \item $C$ on havaittu luokka
    \end{itemize}
    \item epärealistisesta yksinkertaistuksesta huolimatta Naivé Bayes kilpailee tarkkuudella hienostuneempien tekniikoiden kanssa\cite{rish2001empirical}
    \item toimii parhaiten kun syötteet ovat tilastollisesti riippumattomia, tai kun syötteet ovat funktionaalisesti riippuvaisia toisistaan
    \item tarkkuus ei korreloidu syötteiden määrään, vaan korreloi yksinkertaisuudessa menetetyn tiedon määrään
    \item Bayes-optimaalinen luokittelija pyrkii maksimoimaan posteriori todennäköisyyden kullekin luokalle $C$, jonka perusteella se tekee ennusteensa todennäköiselle luokalle
    \begin{itemize}
        \item diskriminanttina funktiona: $f^*_i(\textbf{x}) = P(\textbf{X}=\textbf{x} | C=i) P(C=i)$
        \item toisin sanoen siis: $BO(\textbf{x}) = \arg \max_i P(\textbf{X} = \textbf{x}|C=i) P(C = i)$
        \item koska kyseessä on ehdollinen todennäköisyys ja ennustavana tekijänä on havaintovektori $\textbf{x}$, on havainnon piirteiden määrän kasvaessa $P(\textbf{X} = \textbf{x} | C = i)$ Bayes-optimaalinen luokittelija laskennallisesti raskas prosessi
        \item tämän vuoksi suoraan laskemisen sijasta käytetään jonkinlaisia estimaatteja tai yksinkertaistuksia, joihin naive Bayes lukeutuu
    \end{itemize}
    \item Naive Bayes diskriminanttina funktiona: $f^{NB}_i(\textbf{x}) = \Pi^n_{j=1} P(X_j=x_j | C=i) P(C=i)$
    \begin{itemize}
        \item jossa $j$ vastaa havaintojen ulottuvuuksia
    \end{itemize}
    \item rajoituksia nominaalisten piirteiden kanssa: arvot joita on rajallinen määrä, ja piirteiden eri arvot voidaan vaihtaa omaan indeksiinsä
    \begin{itemize}
        \item binääriset: vain lineaarisia funktioita
        \item useampi-arvoinen piirre: jonkin asteista polynomista oppimista. Vaikka olisi polynomisesti eroteltavissa, ei silti ole riittävää
    \end{itemize}
\end{itemize}
\end{document}
